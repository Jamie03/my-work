<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=false><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Generative AI in Language Learning: User Testing Findings &#183; You found me!</title><meta name=title content="Generative AI in Language Learning: User Testing Findings &#183; You found me!"><meta name=description content="Key insights from three rounds of user testing for a generative AI language learning prototype, covering UI tweaks, feature evolution, and engagement strategies."><meta name=keywords content="AI Language Learning,ICALL,Scenario-Based Learning,UX Design,Findings,"><link rel=canonical href=https://Jamie03.github.io/my-work/posts/1748099731762-sla-findings/><link type=text/css rel=stylesheet href=/my-work/css/main.bundle.min.547f5ba2058f744a2cb610c58442178d18e58cf0a881d7e80f0eadacb62f64e62c232f27f522d2471553ffb7890958a2bfaf8e96b1d576611840d313bbf3d912.css integrity="sha512-VH9bogWPdEosthDFhEIXjRjljPCogdfoDw6trLYvZOYsIy8n9SLSRxVT/7eJCViiv6+OlrHVdmEYQNMTu/PZEg=="><script type=text/javascript src=/my-work/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/my-work/js/main.bundle.min.f8f2cec11308434554dfdbe3a0963bc19265192ebb9e2d644f3f9250731c879dfb09b44d2d58fcd06e8a1c9051b57f594719b37d21689d366ffd2db050df40a0.js integrity="sha512-+PLOwRMIQ0VU39vjoJY7wZJlGS67ni1kTz+SUHMch537CbRNLVj80G6KHJBRtX9ZRxmzfSFonTZv/S2wUN9AoA==" data-copy=Copy data-copied=Copied></script><script src=/my-work/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj+Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script><link rel=apple-touch-icon sizes=180x180 href=/my-work/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/my-work/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/my-work/favicon-16x16.png><link rel=manifest href=/my-work/site.webmanifest><meta property="og:url" content="https://Jamie03.github.io/my-work/posts/1748099731762-sla-findings/"><meta property="og:site_name" content="You found me!"><meta property="og:title" content="Generative AI in Language Learning: User Testing Findings"><meta property="og:description" content="Key insights from three rounds of user testing for a generative AI language learning prototype, covering UI tweaks, feature evolution, and engagement strategies."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-08T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-08T00:00:00+00:00"><meta property="article:tag" content="AI Language Learning"><meta property="article:tag" content="ICALL"><meta property="article:tag" content="Scenario-Based Learning"><meta property="article:tag" content="UX Design"><meta property="article:tag" content="Findings"><meta property="og:image" content="https://Jamie03.github.io/my-work/posts/1748099731762-sla-findings/featured.png"><meta property="og:see_also" content="https://Jamie03.github.io/my-work/posts/1748174596182-sla-findings/"><meta property="og:see_also" content="https://Jamie03.github.io/my-work/posts/1748091371063-icall-method/"><meta property="og:see_also" content="https://Jamie03.github.io/my-work/posts/1748010464372-genai-icall/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Jamie03.github.io/my-work/posts/1748099731762-sla-findings/featured.png"><meta name=twitter:title content="Generative AI in Language Learning: User Testing Findings"><meta name=twitter:description content="Key insights from three rounds of user testing for a generative AI language learning prototype, covering UI tweaks, feature evolution, and engagement strategies."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"Generative AI in Language Learning: User Testing Findings","headline":"Generative AI in Language Learning: User Testing Findings","description":"Key insights from three rounds of user testing for a generative AI language learning prototype, covering UI tweaks, feature evolution, and engagement strategies.","inLanguage":"en","url":"https:\/\/Jamie03.github.io\/my-work\/posts\/1748099731762-sla-findings\/","author":{"@type":"Person","name":"Jose Maria Santiago III"},"copyrightYear":"2023","dateCreated":"2023-07-08T00:00:00\u002b00:00","datePublished":"2023-07-08T00:00:00\u002b00:00","dateModified":"2023-07-08T00:00:00\u002b00:00","keywords":["AI Language Learning","ICALL","Scenario-Based Learning","UX Design","Findings"],"mainEntityOfPage":"true","wordCount":"1834"}]</script><meta name=author content="Jose Maria Santiago III"><link href=https://github.com/Jamie03 rel=me><link href=https://www.linkedin.com/in/jmsantiagoiii/ rel=me><link href=https://orcid.org/0000-0002-4730-7865 rel=me><script src=/my-work/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div><a href=/my-work/ class=flex><span class=sr-only>You found me!</span>
<img src=/my-work/icons8-dice-70.png width=35 height=35 class="logo max-h-[5rem] max-w-[5rem] object-scale-down object-left nozoom" alt="You found me!"></a></div><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/my-work/ class="text-base font-medium text-gray-500 hover:text-gray-900">You found me!</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/my-work/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>research</p></a><a href="https://drive.google.com/file/d/1EoxCVCWjmhsJ8w-8b0KPRmYt3qVLKfKO/view?usp=sharing" target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>resume</p></a><a href=/my-work/worlds/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>world-building</p></a><a href=https://orcid.org/0000-0002-4730-7865 target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M294.75 188.19h-45.92V342h47.47c67.62.0 83.12-51.34 83.12-76.91.0-41.64-26.54-76.9-84.67-76.9zM256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm-80.79 360.76h-29.84v-207.5h29.84zm-14.92-231.14a19.57 19.57.0 1119.57-19.57 19.64 19.64.0 01-19.57 19.57zM3e2 369h-81V161.26h80.6c76.73.0 110.44 54.83 110.44 103.85C410 318.39 368.38 369 3e2 369z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://www.linkedin.com/in/jmsantiagoiii/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/my-work/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>research</p></a></li><li class=mt-1><a href="https://drive.google.com/file/d/1EoxCVCWjmhsJ8w-8b0KPRmYt3qVLKfKO/view?usp=sharing" target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>resume</p></a></li><li class=mt-1><a href=/my-work/worlds/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>world-building</p></a></li><li class=mt-1><a href=https://orcid.org/0000-0002-4730-7865 target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M294.75 188.19h-45.92V342h47.47c67.62.0 83.12-51.34 83.12-76.91.0-41.64-26.54-76.9-84.67-76.9zM256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm-80.79 360.76h-29.84v-207.5h29.84zm-14.92-231.14a19.57 19.57.0 1119.57-19.57 19.64 19.64.0 01-19.57 19.57zM3e2 369h-81V161.26h80.6c76.73.0 110.44 54.83 110.44 103.85C410 318.39 368.38 369 3e2 369z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://www.linkedin.com/in/jmsantiagoiii/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/my-work/posts/1748099731762-sla-findings/featured_hu_1d4d7bff78ba286.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Generative AI in Language Learning: User Testing Findings</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2023-07-08T00:00:00+00:00>8 July 2023</time><span class="px-2 text-primary-500">&#183;</span><span>1834 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">9 mins</span><span class="px-2 text-primary-500">&#183;</span>
<script type=text/javascript src=/my-work/js/zen-mode.min.eea5245cf9244ecbdf2c150d1c8833226c1541cadf6e98f63a7c9192b1a3676df2c3ec603b14f4cfaaa53971fd9d8955640c0f405bf3de2b43ee7a5fb29ae721.js integrity="sha512-7qUkXPkkTsvfLBUNHIgzImwVQcrfbpj2OnyRkrGjZ23yw+xgOxT0z6qlOXH9nYlVZAwPQFvz3itD7npfsprnIQ=="></script><span class=mb-[2px]><span id=zen-mode-button class="text-lg hover:text-primary-500" title="Enable zen mode" data-title-i18n-disable="Enable zen mode" data-title-i18n-enable="Disable zen mode"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 50 50" width="50" height="50"><path fill="currentColor" d="M12.980469 4C9.1204688 4 5.9804688 7.14 5.9804688 11L6 26H9.9804688V11c0-1.65 1.3400002-3 3.0000002-3H40.019531c1.66.0 3 1.35 3 3V39c0 1.65-1.34 3-3 3H29c0 1.54-.579062 2.94-1.539062 4H40.019531c3.86.0 7-3.14 7-7V11c0-3.86-3.14-7-7-7H12.980469zM7 28c-2.206.0-4 1.794-4 4V42c0 2.206 1.794 4 4 4H23c2.206.0 4-1.794 4-4V32c0-2.206-1.794-4-4-4H7zm0 4H23L23.001953 42H7V32z"/></svg></span></span></span></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/my-work/tags/ai-language-learning/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Language Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/my-work/tags/icall/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ICALL
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/my-work/tags/scenario-based-learning/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Scenario-Based Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/my-work/tags/ux-design/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">UX Design
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/my-work/tags/findings/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Findings</span></span></span></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#our-design-journey-iterations-incoming>Our Design Journey: Iterations Incoming!</a><ul><li><a href=#first-iteration-a-promising-start>First Iteration: A Promising Start</a></li><li><a href=#second-iteration-sharpening-the-experience>Second Iteration: Sharpening the Experience</a></li><li><a href=#third-iteration-forward-thinking>Third Iteration: Forward Thinking</a></li></ul></li><li><a href=#what-did-we-learn>What Did We Learn?</a><ul><li><a href=#text-vs-voice-different-paths-same-goal>Text vs. Voice: Different Paths, Same Goal</a></li><li><a href=#why-scenario-based-practice-matters>Why Scenario-Based Practice Matters</a></li><li><a href=#the-limits-of-a-standalone-experience>The Limits of a Standalone Experience</a></li></ul></li><li><a href=#we-learned-now-what>We Learned, Now What?</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#our-design-journey-iterations-incoming>Our Design Journey: Iterations Incoming!</a><ul><li><a href=#first-iteration-a-promising-start>First Iteration: A Promising Start</a></li><li><a href=#second-iteration-sharpening-the-experience>Second Iteration: Sharpening the Experience</a></li><li><a href=#third-iteration-forward-thinking>Third Iteration: Forward Thinking</a></li></ul></li><li><a href=#what-did-we-learn>What Did We Learn?</a><ul><li><a href=#text-vs-voice-different-paths-same-goal>Text vs. Voice: Different Paths, Same Goal</a></li><li><a href=#why-scenario-based-practice-matters>Why Scenario-Based Practice Matters</a></li><li><a href=#the-limits-of-a-standalone-experience>The Limits of a Standalone Experience</a></li></ul></li><li><a href=#we-learned-now-what>We Learned, Now What?</a></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><details style=margin-left:0 class="mt-2 mb-5 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5"><summary class="py-1 text-lg font-semibold cursor-pointer bg-primary-200 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-primary-800 dark:text-neutral-100">AI for Scenario-Based Learning - This article is part of a series.</summary><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><a href=/my-work/posts/1748010464372-genai-icall/>Part 1: From Drills to Dialogues: A New Era for Language Learners</a></div><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><a href=/my-work/posts/1748091371063-icall-method/>Part 2: Designing an AI-Driven Language Learning Tool</a></div><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">Part 3: This Article</div><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><a href=/my-work/posts/1748174596182-sla-findings/>Part 4: Design Guidelines: What Makes an AI Language Tool Work?</a></div></details><div class="article-content max-w-prose mb-20"><p>Photo by <a href="https://unsplash.com/@uxindo?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" target=_blank>UX Indonesia</a> on <a href="https://unsplash.com/photos/person-in-blue-long-sleeve-shirt-using-black-laptop-computer-5QiGvmyJTsc?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" target=_blank>Unsplash</a></p><h2 class="relative group">Introduction<div id=introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#introduction aria-label=Anchor>#</a></span></h2><p>When we first set out to design a <a href=https://Jamie03.github.io/my-work/posts/1748091371063-icall-method/ target=_blank>generative AI-powered language learning tool</a>, our goal wasn’t just to build something cool with using multiple AI modules. We wanted to create something that helps people improve at speaking a new language in a way that feels natural and maybe even a little fun.</p><p>So, we built a <a href=https://github.com/NesR0M/AiCall_ResearchProjectSS23 target=_blank>prototype</a>. We then handed it over to a group of language learners to see what worked, what didn’t, and what still needed improvement. Instead of doing one big test, we ran three iterative sessions. Why? Because learning (and designing for learning) is never a straight line. It’s messy, layered, and constantly evolving.</p><p>In each round, we listened closely to what participants said (and didn’t say), how they used the tool, where they got stuck, and what sparked their curiosity. Their feedback helped shape a better prototype and form a deeper understanding of what learners want when using AI to practice a language.</p><p>This article covers what we found along the way and what aspects of the tool needed improvements. Whether you’re an educator, a developer, or just curious about how AI can help us learn better, I hope these insights give you a window into making a digital language partner feel like it belongs in your life.</p><hr><h2 class="relative group">Our Design Journey: Iterations Incoming!<div id=our-design-journey-iterations-incoming class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#our-design-journey-iterations-incoming aria-label=Anchor>#</a></span></h2><p>To bring you up to speed, our testing process was split into three weekly feedback sessions, each building on the last. We brought in real German language learners to try out the prototype, share their thoughts, and help us shape it into something more useful and intuitive.</p><p>Each session followed a simple rhythm: <strong>test</strong>, <strong>talk</strong>, <strong>improve</strong>. Participants explored the tool and shared their experiences through interviews and creative feedback exercises. After each round, we made focused updates based on what users wanted most and what we could realistically implement in time.</p><p>This iterative setup allowed us to gather deeper insights than a one-off test ever could. By the third session, users reflected on its potential and how they could implement a similar tool in their typical setups. And that’s where the most valuable feedback came from.</p><h3 class="relative group">First Iteration: A Promising Start<div id=first-iteration-a-promising-start class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#first-iteration-a-promising-start aria-label=Anchor>#</a></span></h3><p>When we launched our first testing session, we weren’t sure what to expect but were <strong>eager</strong> to see how learners would respond to the early version of our prototype. Thankfully, they didn’t hold back.</p><p><figure><img class="my-0 rounded-md" loading=lazy srcset="/my-work/first_iteration_hu_4c32b8e227706645.png 330w,
/my-work/first_iteration_hu_4769ab93487e69b0.png 660w,
/my-work/first_iteration_hu_189f07d7a8cb6e8b.png 1024w,
/my-work/first_iteration_hu_f7974cc15d1aa5ad.png 2x" data-zoom-src=/my-work/first_iteration_hu_f7974cc15d1aa5ad.png src=/my-work/first_iteration_hu_4769ab93487e69b0.png alt="First iteration of the ICALL prototype in a café scenario"><figcaption>First iteration of the prototype showing the café roleplay scenario with AI conversational agent and dynamic background</figcaption></figure></p><p>Right off the bat, participants appreciated the <em>flexibility</em> in choosing different scenarios and the option to switch between typing and speaking. The <strong>voice recording</strong> feature, in particular, stood out. For many, it felt like a <em>low-pressure</em> way to practice speaking without worrying about making mistakes in front of others. One user even mentioned that talking to an AI felt <em>less intimidating</em> than speaking in class.</p><p><a href=https://github.com/openai/whisper target=_blank>Whisper</a> (the speech-to-text engine we used) earned some unexpected praise. It often glossed over small spelling mistakes in transcriptions, which had a surprising side effect: learners felt more confident trying out <strong>complex vocabulary</strong> and sentence structures. When the tool didn’t penalize minor errors, they took more risks. <em>This is exactly the kind of learning behavior we want to encourage.</em></p><p>That said, the first version of the prototype had its fair share of <em>rough edges</em>. Learners noted that the interface focused too much on text input, with little feedback or guidance to help them get started. The <strong>robotic voice</strong> used for text-to-speech made conversations feel <em>stiff</em> and <em>unnatural</em>. They also critiqued the visuals, which failed to <em>immerse</em> our learners.</p><p>Our testers also felt the AI was too <em>passive</em> during conversations. Too often, they were left carrying the dialogue with minimal input from the virtual partner. Their feedback was clear: the tool needed to feel more like a <em>real conversation</em> and less like typing into a form. From that first round, a few key ideas started to emerge:</p><ol><li><strong>More dynamic AI dialogue</strong></li><li><strong>Clearer onboarding and feedback</strong></li><li><strong>Larger chat window</strong></li><li><strong>Adjustable language complexity</strong></li><li><strong>“Hover to translate”</strong> for immediate word help</li></ol><p>We had our work cut out for us: a solid start that proves our concept for a scenario-based ICALL app, but with a handful of <em>high-priority</em> improvements ahead.</p><h3 class="relative group">Second Iteration: Sharpening the Experience<div id=second-iteration-sharpening-the-experience class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#second-iteration-sharpening-the-experience aria-label=Anchor>#</a></span></h3><p>Equipped with feedback from the first round, we went back to the drawing board to come up with a more <strong>polished</strong> version of the prototype. This second iteration was about <em>smoothing the rough edges</em> and making the experience feel more like a <em>real</em> language-learning tool, not just a tech demo.</p><p><figure><img class="my-0 rounded-md" loading=lazy srcset="/my-work/second_iteration_hu_5687004f5b2f511c.png 330w,
/my-work/second_iteration_hu_2cf20400e8adaa43.png 660w,
/my-work/second_iteration_hu_d28adc17edf33ea.png 1024w,
/my-work/second_iteration_hu_a9b529cb4b0b2b1b.png 2x" data-zoom-src=/my-work/second_iteration_hu_a9b529cb4b0b2b1b.png src=/my-work/second_iteration_hu_2cf20400e8adaa43.png alt="Second iteration of the ICALL prototype in a bakery scenario"><figcaption>Second iteration of the prototype showing the bakery roleplay with a refined UI: larger chat window, prominent microphone icon, and decoupled, faster image generation</figcaption></figure></p><p>One of our first moves was to revamp the interface:</p><ul><li><strong>Bigger text output box</strong> and a bolder microphone icon to nudge users toward the speaking mode they favored.</li><li><strong>Decoupled</strong> dialogue output from image generation, resulting in noticeably faster response times.</li></ul><p>Under the hood, we also replaced <strong><a href=https://pypi.org/project/gTTS/ target=_blank>gTTS</a></strong> with <strong><a href=https://elevenlabs.io/ target=_blank>ElevenLabs Voice AI</a></strong> for far more <em>natural-sounding</em> speech. We hesitated at first, but repeated comments on the old audio’s uncanniness convinced us this change was essential.</p><p>Next, we optimized our prompts for both <strong><a href=https://github.com/CompVis/stable-diffusion target=_blank>Stable Diffusion</a></strong> and <strong><a href=https://openai.com/product/gpt-4 target=_blank>GPT-4</a></strong>. By adding a rule to center a character in each image, we gave learners a clear visual partner. And by tweaking the AI’s dialogue to be shorter and end with questions, conversations felt <em>more dynamic</em> and <em>human</em>.</p><p>We also introduced:</p><ul><li><strong>Visual language correction</strong> for on-screen grammar and vocabulary hints</li><li><strong>Subtle audio feedback</strong> to reinforce progress and make the tool feel truly responsive</li></ul><p>Although our planned translation feature was postponed, participants loved the new <strong>conversation history panel</strong>, and many said the language corrections made the app feel like a <em>real</em> learning environment.</p><p>A clear theme emerged: users wanted AI responses that matched their <strong>proficiency level</strong>. Some found the tool too advanced, others too simple. This insight planted the seed for our next big feature: <strong>adaptive AI responses</strong> tuned to each learner’s skill.</p><p>The second iteration was a major leap forward. The prototype felt faster, smarter, and most importantly, more <em>usable</em>.</p><h3 class="relative group">Third Iteration: Forward Thinking<div id=third-iteration-forward-thinking class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#third-iteration-forward-thinking aria-label=Anchor>#</a></span></h3><p>By the time we reached our third and final iteration, the prototype had come a long way. Aside from fixing bugs or tweaking features, this round was also about asking bigger questions: <strong>How well does the tool support learners in the long term?</strong> and <strong>What should come next?</strong></p><p><figure><img class="my-0 rounded-md" loading=lazy srcset="/my-work/third_2_hu_affea5b69dab0a81.png 330w,
/my-work/third_2_hu_56975dce9608fc9e.png 660w,
/my-work/third_2_hu_840a13949192d17a.png 1024w,
/my-work/third_2_hu_918d2d4dba64483b.png 2x" data-zoom-src=/my-work/third_2_hu_918d2d4dba64483b.png src=/my-work/third_2_hu_56975dce9608fc9e.png alt="Third iteration of the ICALL prototype in a restaurant scenario"><figcaption>Third iteration of the prototype showing the romantic restaurant roleplay with portrait layout, click to translate feature, expanded chat area, and on-demand translation panel</figcaption></figure></p><p>We started by refreshing the interface once again. The text output area was expanded, and we switched to a portrait-oriented image layout that placed more visual emphasis on the scenario, another step we took towards better learner immersion.</p><p>We also added a highly requested feature: <strong>click-to-translate</strong>! Powered by the <a href=https://www.deepl.com/docs-api target=_blank>DeepL API</a>, this let learners translate full sentences in the chat at a single tap. While participants loved the convenience, several noted they’d actually prefer translating individual words during active practice.</p><p>Based on feedback, the new UI landed well as learners appreciated the cleaner layout, extra icons, and expanded chat space. Still, they spotted areas for polish:</p><ul><li><strong>Clearer sender distinction</strong> between user and AI messages</li><li>A more <strong>modern, app-like visual style</strong></li><li>Filling the startup screen’s white space with <strong>conversation history</strong></li></ul><p>Our scenario visuals also improved in clarity and relevance, but users craved even more engagement. Ideas included:</p><ul><li><strong>Animated avatars</strong> or expressive feedback (e.g., changing facial expressions)</li><li>Deeper AI “presence” through local memory or emotional cues</li></ul><p>That didn’t stop them from dreaming up bold next steps:</p><ul><li><strong>Gamification features</strong> to boost motivation</li><li><strong>Improved onboarding</strong> for first-time users</li><li><strong>Customizable scenarios</strong> tailored to individual goals</li><li><strong>Vocabulary suggestions</strong> to bridge learning gaps</li></ul><p>This final round made one thing clear: while the core of the tool is solid, there’s a real opportunity to build something even more <strong>personalized</strong>, <strong>engaging</strong>, and <strong>emotionally intelligent</strong>. Thanks to our participants’ thoughtful feedback, we now have a clear roadmap for making it happen.</p><hr><h2 class="relative group">What Did We Learn?<div id=what-did-we-learn class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#what-did-we-learn aria-label=Anchor>#</a></span></h2><p>Throughout all three iterations, one thing became increasingly clear: <strong>how people interact with the tool matters as much as what the tool can do.</strong></p><h3 class="relative group">Text vs. Voice: Different Paths, Same Goal<div id=text-vs-voice-different-paths-same-goal class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#text-vs-voice-different-paths-same-goal aria-label=Anchor>#</a></span></h3><p>When it came to communication style, participants naturally split into two camps:</p><ul><li><strong>Typing enthusiasts</strong></li><li><strong>Speaking aficionados</strong></li></ul><p>Each had its strengths, but <strong>speech-to-text (STT)</strong> emerged as a sleeper hit. Thanks to <a href=https://github.com/openai/whisper target=_blank>Whisper</a>, even slightly mispronounced words were transcribed accurately, giving learners a confidence boost to experiment with new vocabulary. Better inputs led to richer, more coherent outputs from <a href=https://openai.com/product/gpt-4 target=_blank>GPT-4</a>.</p><p><strong>The takeaway?</strong> Giving learners flexible and forgiving ways to communicate helps lower the barrier to participation and opens up space for real growth. However, this is a <strong>double-edged sword</strong>, since proper communication requires proper pronunciation of words and phrases, which the tool cannot detect currently.</p><h3 class="relative group">Why Scenario-Based Practice Matters<div id=why-scenario-based-practice-matters class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#why-scenario-based-practice-matters aria-label=Anchor>#</a></span></h3><p>Across the board, users leaned into <strong>scenario-based learning</strong>. They valued speaking through a scene instead of just typing, noting the record function created a <strong>natural, low-pressure</strong> environment.</p><blockquote><p><em>“It felt less intimidating than speaking in a classroom.”</em></p></blockquote><p>Without classmates to impress or teachers to interrupt, learners felt free to shape conversations. This judgment-free space translated into real confidence and motivation.</p><h3 class="relative group">The Limits of a Standalone Experience<div id=the-limits-of-a-standalone-experience class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#the-limits-of-a-standalone-experience aria-label=Anchor>#</a></span></h3><p>Not every hurdle could be cleared. As novelty wore off, two challenges emerged:</p><ol><li><p><strong>Motivation</strong>: While some used the tool to prep for exams, many struggled to stay consistent on their own. Maybe integrating gamification techniques, like reminders, rewards, or progress tracking, could encourage regular use.</p></li><li><p><strong>AI Personality</strong>: Learners described the chatbot as “faceless” and lacking emotional depth, memory, or character. A potential solution: add intuitive design elements, clearer guidance, or even a bit of personality (avatars, emotional cues) to make the tool feel alive.</p></li></ol><p>These insights confirmed that a great AI tutor needs both <strong>technical power</strong> and a <strong>human touch</strong> to truly engage learners.</p><hr><h2 class="relative group">We Learned, Now What?<div id=we-learned-now-what class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line:none !important" href=#we-learned-now-what aria-label=Anchor>#</a></span></h2><p>After three quick rounds of testing, we learned that user feedback is the fastest path from prototype to a helpful language partner. Letting learners switch between typing and speaking and framing practice as mini-scenarios made them more confident and curious. Speeding up responses, adding on-screen hints, and tuning speech quality showed that a tool’s polish matters as much as its AI core. Yet we also saw that without motivation boosters or a bit of personality, language learners quickly lost the novelty factor of the tool.</p><p>Next, we’ll turn these lessons into concrete design guidelines for <strong>your generative AI tool</strong>. In the next article, you’ll discover how to pick and combine <em>speech</em>, <em>vision</em>, and <em>language modules</em>, structure user flows that keep learners coming back, and sprinkle in gamification or avatars to make each session feel alive!</p><blockquote><p><em>Remember to check out the tool in our <a href=https://github.com/NesR0M/AiCall_ResearchProjectSS23 target=_blank>Github</a>!</em></p></blockquote><p><strong>Interested in my research?</strong> The take a look at <a href=https://orcid.org/0000-0002-4730-7865 target=_blank>my other works</a> that cover topics ranging from using <em>AI in Live-Prototyping Studies</em> to <em>Affective State Change using Haptics</em>!</p></div><details style=margin-left:0 class="mt-2 mb-5 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5"><summary class="py-1 text-lg font-semibold cursor-pointer bg-primary-200 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-primary-800 dark:text-neutral-100">AI for Scenario-Based Learning - This article is part of a series.</summary><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><a href=/my-work/posts/1748010464372-genai-icall/>Part 1: From Drills to Dialogues: A New Era for Language Learners</a></div><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><a href=/my-work/posts/1748091371063-icall-method/>Part 2: Designing an AI-Driven Language Learning Tool</a></div><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">Part 3: This Article</div><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><a href=/my-work/posts/1748174596182-sla-findings/>Part 4: Design Guidelines: What Makes an AI Language Tool Work?</a></div></details></div><script>var oid="views_posts/1748099731762-sla-findings/index.md",oid_likes="likes_posts/1748099731762-sla-findings/index.md"</script><script type=text/javascript src=/my-work/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/my-work/posts/1748091371063-icall-method/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Designing an AI-Driven Language Learning Tool</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2023-07-07T00:00:00+00:00>7 July 2023</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/my-work/posts/1748174596182-sla-findings/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Design Guidelines: What Makes an AI Language Tool Work?</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2023-07-09T00:00:00+00:00>9 July 2023</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href title></a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">© 2025 Jose Maria Santiago III. Content licensed under <a href=https://creativecommons.org/licenses/by-sa/4.0/ target=_blank>CC BY-SA 4.0</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/my-work/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://Jamie03.github.io/my-work/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>