[{"content":" üëã About Me # Greetings! my name is JM, and I aim to design a better tomorrow. By exploring new technologies, I strive to build innovative tools and craft thoughtful experiences that enrich our daily lives.\nWe learn something new every day, but I believe it\u0026rsquo;s our responsibility to share and apply those insights to drive positive change. I\u0026rsquo;m always looking to collaborate with like-minded individuals and groups, so if you\u0026rsquo;d like to work together, send me an invite!\nüßô‚Äç‚ôÇÔ∏è Creative Pursuits # In my free time, I love to build fantasy worlds for an ongoing tabletop role-playing game (TTRPG) campaign with friends and colleagues. I\u0026rsquo;m drawn to classical high-fantasy settings inspired by Tolkien, with a particular focus on political intrigue to drive storytelling.\nOne day, I hope to compile these adventures into a short novel, featuring a collection of themes and stories meant to inspire other hobby writers like myself.\nüöÄ Let‚Äôs Create Together # Whether it‚Äôs through research, world-building, or design, I hope your visit here sparks inspiration for your own creative journey. Thanks for stopping by and I hope we build something great together!\n","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/","section":"","summary":"","title":"","type":"page"},{"content":" ‚úçÔ∏è Research # Here is a collection of research work I\u0026rsquo;ve done throughout the years. Most of the work here feature peer-reviewed work and their corresponding publication links. I also add my own thoughts and give background context when I was working on them!\n","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/posts/","section":"","summary":"","title":"","type":"posts"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/series/ai-in-ttrpgs/","section":"Series","summary":"","title":"AI in TTRPGs","type":"series"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/tags/community-engagement/","section":"Tags","summary":"","title":"Community Engagement","type":"tags"},{"content":"Photo by Jack B on Unsplash\nIntroduction # In recent years, we have witnessed an unprecedented expansion in digital tabletop role-playing game (TTRPG) platforms due to the pandemic and lockdown procedures across the globe. At the same time, generative AI technologies continue to encroach upon the realm of creativity, from AI text and image generation used for fantasy character creation to live session-note automation for summaries. However, the adoption of these tools isn\u0026rsquo;t as prevalent as other digital tools. As mentioned in my previous article on Gathering Community Insights on Tabletop Creativity, while most hobbyists have integrated digital tools into their gaming ecosystems, less than half are considering generative AI to address creative challenges. I wanted to investigate this apprehension further by conducting a more in-depth user study by interviewing experienced players and Game Masters (GMs) to address these questions:\nDigital Integration: How do players and GMs blend traditional methods with digital tools during gameplay? AI Assistance: In what ways can generative AI relieve routine burdens while preserving the integrity of creative processes? This user study delves into how they navigate this hybrid analog‚Äìdigital landscape and how they envision AI as a collaborative partner in the creative storytelling process.\nWho‚Äôs in Our Party? # Four brave adventurers were purposely sampled for this study based on their TTRPG experience in both roles:\nThe Scout: Primarily a player with 3 years of experience; uses analog notes alongside D\u0026amp;D Beyond and Roll20; minimal AI for image generation. The Knight: Newly appointed GM with a total experience of 4 years; background in game design; digital-first, using Foundry VTT, Discord and Figma; AI only for technical support, not creativity. The Mage: Experienced GM of 8 years; extensive digital ecosystem including Roll20, D\u0026amp;D Beyond and Notion; actively uses AI-generated text and art. The Hermit: Seasoned GM with 12 years of experience; prefers hybrid sessions using analog tools (maps, dice towers) alongside digital platforms such as Spotify and Miro; AI used strictly for administrative tasks. The goal of this sampling was to get perspectives from various roles and experience levels while considering their unique gaming setups. With this in mind, let‚Äôs jump into the fray and see what awaits these four.\nBlending Dice and Devices # When face-to-face sessions dried up in 2020, virtual play rocketed into the mainstream, shining a spotlight on virtual tabletops (VTTs) like Roll20. The Scout and Hermit described missing the tactile feeling of physical dice rolls and hand-scrawled maps for in-person immersion. Yet they were open to using digital initiative trackers and dynamic stat blocks when their sessions went online. They shared moments of scribbling faction notes on paper one second, then clicking ‚ÄúNext‚Äù on a VTT macro the next. Having largely returned to analog sessions, the Hermit still retains digital conveniences adopted during lockdown.\nAI as the New Quartermaster # Our digital tool specialists, the Knight and Mage, have carved out distinct AI roles at their tables. The Mage leans into generative text and image tools to help them sketch NPCs and locales, then refines the output to preserve each campaign‚Äôs tone. By contrast, the Knight uses AI strictly for menial tasks, such as automated loot tables, session reminders, and rule lookups. Across the interviews, each participant expressed excitement for AI-enhanced workflows, like automatically transcribing session audio into recaps or creating fantasy maps that perfectly fit the scenario the players find themselves in, potentially saving precious preparation time.\nHuman Creativity First # Despite the allure of instant content generation, every party member insisted that AI must be a supporting actor, not the star. They highlighted the need for:\nCustomizable output: Maps, loot tables, or character backstories must be tweakable to ensure each campaign retains its unique flavor. Ethical considerations: Transparency in how AI assets are generated Fairness and bias checks User agency and ownership of creative content Concerns about generic, one-size-fits-all generators mirror broader debates over AI-asset ownership and creative bias. Ethical frameworks emphasize that transparency, fairness, and user agency are non-negotiable when using generative AI in collaborative storytelling.\nConclusion and Future Directions # Our four adventurers show that the sweet spot of modern TTRPGs lies where the clatter of physical dice meets the click of digital tools. AI tools should retain a supportive role rather than become the dominant creative force, unless explicitly prompted. Whether it‚Äôs the Hermit switching between hand-drawn maps and VTT macros or the Mage refining AI-designed NPCs into bespoke story elements, everyone agrees: AI must listen before it speaks.\nImagine a co-creative AI that not only suggests campaign-appropriate plot hooks and dynamic world details, but also exposes the logic behind each idea, enforces bias checks, wrapped in an ethical framework that puts you in control. That‚Äôs the vision I want to explore in the next article, where we dive into designing an AI-assisted world-building tool built to spark richer, more collaborative storytelling at every roll of the dice!\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/posts/1747751250571-interview/","section":"","summary":"","title":"Exploring Hybrid Setups \u0026 AI for Tabletop Creativity","type":"posts"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/tags/generative-ai/","section":"Tags","summary":"","title":"Generative AI","type":"tags"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/tags/ttrpg/","section":"Tags","summary":"","title":"TTRPG","type":"tags"},{"content":"","date":"20 May 2025","externalUrl":null,"permalink":"/my-work/tags/user-study/","section":"Tags","summary":"","title":"User Study","type":"tags"},{"content":"Photo by Joseph Ogbonnaya on Unsplash\nIntroduction # When was the last time you saw your tabletop group light up with fresh ideas? Designing unforgettable characters and crafting epic plot twists draws all types of players towards Tabletop Role-Playing Games (TTRPGs). The creative freedom offered in TTRPG systems is unique and can only be experienced when partaking in the medium. However, as I explored in my previous article on A New Era for Tabletop Role-Playing Games, creative hurdles often hold players back despite having that freedom. This issue is further complicated by the fact that every playgroup has its own unique setups and ways of working.\nTo better understand how players and Game Masters (GMs) experience that creative magic, I ran a survey to gather nuanced perspectives on creative expression and its challenges. Over thirty seasoned hobbyists shared their backgrounds, triumphs, frustrations, and hopes for tools to enhance creativity and make the next campaign more vivid.\nCreative Freedom and Player Agency # It turns out that, by and large, this community feels creatively free. Nearly three-quarters rated their ability to express ideas at the table as a top-tier 4 or 5 out of 5, and an even greater share felt they had agency in shaping the story. That sense of ownership is the lifeblood of TTRPGs: when players know their choices matter, they become more invested in the adventure and the narrative.\nYet even in a creative paradise, clouds can gather. On average, participants rated the impact of creative hurdles around the midpoint, suggesting that frustrations still linger with varied intensity. When asked which challenges they frequently come across, three stand out:\nTime Constraints: Nearly half struggle to carve out preparation time consistently. Complex Rules \u0026amp; Mechanics: Over a third find dense rulebooks a creative drag. Narrative Bottlenecks: One in three feel the GM‚Äôs vision sometimes dominates, leaving personal ideas sidelined. Beyond those top-line stats, many mentioned session fatigue and clashing player styles. Only a select few felt they never hit a creative snag, proving that even veteran groups can use a helping hand.\nDigital Companions and the AI Question # Digital tools are already woven into many campaigns and setups. From character-building apps like D\u0026amp;D Beyond to world-building platforms like Obsidian or World Anvil, about 80% of our respondents tap into some online aid. Yet when it comes to AI specifically, the jury is split: just under half are open to AI‚Äôs help, while the rest remain cautious.\nFor those ready to experiment, they outlined the following use cases:\nAmbient Sounds \u0026amp; Music Generation (88% interest) World-Building Assistance (75%) NPC Backstories (81%) Automated Character Sheets (69%) Only about half would welcome AI-driven plot suggestions, which could warrant further investigation. Looking Ahead: A Deeper Dive # The survey makes one thing clear: players and GMs love the creative freedom of tabletop play and already lean on digital tools, but when it comes to AI, there‚Äôs a real sense of caution. Many worry that an over-eager algorithm could dilute the human spark that makes every session unique. Understanding those fears is essential if we want AI to be a trusted companion rather than an oversized game master.\nTo get to the bottom of this, I decided to conduct a focused follow-up study that will explore how analog methods and digital aids coexist around the table and probe how generative AI might shoulder routine tasks‚Äîlike character-sheet upkeep or world-building structure‚Äîwithout stealing the spotlight from player-driven storytelling. By focusing on these questions, I hope to uncover the insights needed to build tools that truly enhance the shared adventure.\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"19 May 2025","externalUrl":null,"permalink":"/my-work/posts/1747666608330-pre-survey/","section":"","summary":"","title":"Community Insights on Tabletop Creativity","type":"posts"},{"content":"","date":"14 May 2025","externalUrl":null,"permalink":"/my-work/tags/hci/","section":"Tags","summary":"","title":"HCI","type":"tags"},{"content":"","date":"14 May 2025","externalUrl":null,"permalink":"/my-work/tags/live-prototyping/","section":"Tags","summary":"","title":"Live Prototyping","type":"tags"},{"content":"Photo by Am√©lie Mourichon on Unsplash\nIntroduction # Picture this: you‚Äôre conducting a typical usability test on a new piece of software, watching a participant click through the polished interface you just designed. You‚Äôve poured hours into wireframes, mockups, and scenario scripts, but as soon as they hit ‚Äúsend,‚Äù the feedback rolls in: ‚ÄúI wish these labels were clearer,‚Äù ‚ÄúCan this answer more naturally?‚Äù Now you‚Äôre back at your desk, juggling design sprints and waiting for the next round of user tests. It‚Äôs a familiar rhythm in user-centered design (UCD), but it can feel more like a marathon than a conversation.\nTraditional UCD methods champion this iterative process: gather user needs, build a prototype, test, tweak, and repeat. While tools like Figma make it easy to spin up high-fidelity screens, real change often waits until ‚Äúafter the study‚Äù when code catches up to ideas. By then, those ‚Äúaha‚Äù moments from participants risk fading into meeting notes or getting lost in the backlog.\nWhat if we could cut that lag down to zero? What if you could tweak the component your user is touching, right as they‚Äôre touching it? That‚Äôs the core of our research question: ‚ÄúHow can generative AI be used to enable live-prototyping within user studies?‚Äù Instead of a human ‚ÄúWizard-of-Oz‚Äù manually swapping screens, what about using generative artificial intelligence (AI) to tweak features and elements of the prototype?\nTo bring this vision to life, we propose a conceptual framework for using generative AI to facilitate live-prototyping. We then conducted a case study with prototyping experts using our framework to run a live session. We gathered their responses to see if this idea is viable in a real-world setting.\nWhere Today‚Äôs Frameworks Fall Short # Even with all the buzz around AI-powered design tools, there‚Äôs still a stubborn lag between hearing what users want and seeing those ideas live in a prototype. Let‚Äôs walk through where today‚Äôs approaches speed things up‚Äîand where they stall out.\nNarrow AI-Prototyping Plugins # PromptInfuser lets you bind UI mock-ups in Figma to LLM prompts, so text inputs spin back AI-generated responses on the same screen. Designers loved catching prompt mismatches early; however, you still have to polish every change by hand, and you‚Äôre limited to text fields, not full interfaces. Text-to-Image Generators like Stable Diffusion and Midjourney produce style ideas or rough mockups, serving as a ‚Äúcatalyst for brainstorming‚Äù rather than final assets. Designers must translate those images into usable UI components, and you can‚Äôt tweak them live in a user session. AI-Assisted Feedback Analysis tools can cluster and summarize user comments after a study, cutting down transcription and coding drudgery. But this still happens after the prototype has been shipped for testing, so design updates remain an offline affair. Big-Picture AI-UCD Frameworks # DesignFusion decomposes design tasks into subcomponents and uses multi-model reasoning to generate concept art, with a mixed-initiative toolkit for designer intervention. It streamlines ideation, but stops short of swapping components during a live test. AI-UCD embeds AI across nine UCD steps, from user research through ethical auditing and validation. It ensures rigorous, data-driven iterations, yet still follows a sequential cycle: test ‚Üí analyze ‚Üí refine. There‚Äôs no mechanism for in-session tweaks. Classic (and AI-Augmented) Wizard-of-Oz # Traditional Wizard-of-Oz experiment uses human ‚Äúwizards‚Äù hidden behind the scenes to fake unbuilt features. It captures real user‚Äìsystem interactions, but operators juggle hotkeys, face fatigue, and introduce inconsistency, which limits scalability. Apprentice of Oz automates subtasks to ease the wizard‚Äôs burden, boosting reliability. However, designers still rely on a human-in-the-loop, and it wasn‚Äôt designed for rapid, multi-model component swaps on the fly. Frameworks like DesignFusion and AI-UCD leverage generative AI to dynamically support ideation and enable multi-model reasoning to build iterative feedback loops. Yet in both cases, prototype changes still wait for ‚Äúafter the test.‚Äù What if you didn‚Äôt have to? Imagine using a quick prompt to tweak the prototype‚Äôs behavior while your participant is still in session. This in-the-moment agility could collapse testing and iteration into one fluid conversation, revealing deeper insights and transforming every usability study into a co-creative exploration.\nIntroducing the AI-of-Oz Framework # Imagine you‚Äôre in the middle of a usability session and your participant pauses, frowns at the screen, and says,\n‚ÄúCould this button look more playful?‚Äù\nInstead of jotting down a note and promising to revisit it later, you flip over to your hidden control panel, tweak a simple prompt:\n‚ÄúMake the button rounder and add a subtle bounce animation.‚Äù\nand hit update. In seconds, the prototype on your user‚Äôs screen shifts to match that request, letting you see in real time whether that playful bounce resonates.\nParticipants interact with the prototype while designers update AI components live using a separate control interface. At the core of this approach is live-prototyping: constructing your interface out of generative AI components that can be created, swapped, or reshaped on demand. As sketched in the figure above, every feature your participant interacts with is driven by one or more AI models‚ÄîGPT powering conversational bits, Stable Diffusion crafting on-the-fly imagery, or other specialized engines for charts, layouts, and even voice. Behind the scenes, you work in a second interface that participants never see. Here, you type clear text prompts for your language model or adjust parameters in a diffusion dashboard, instantly regenerating whatever element needs tweaking.\nBecause the user only ever sees a polished front end, you can experiment freely:\nNeed a completely new illustration? Chain two models together: let one generate background art and feed it into an LLM to produce contextual captions. Want to A/B test button labels, dialog tones, or color schemes? Switch them mid-session and watch which variant sparks that ‚Äúaha‚Äù moment. This method isn‚Äôt just about speed; it‚Äôs about collapsing the traditional test, then iterate later cycle into one fluid exchange. Every piece of feedback becomes an invitation to co-create, and every adjustment deepens your understanding of what truly works. By embedding generative AI directly into your prototyping toolkit, you turn every user study into a live design lab, where ideas evolve on the spot and insights emerge organically.\nConclusion \u0026amp; Next Steps # By integrating generative AI directly into your user sessions, you can transform every study into a live workshop. But as you picture this in your workflow, you might ask yourself:\nHow would a live prototyping session look? How can I design my prototype with the framework in mind? In our paper, we tested our framework in action by flipping the script: we had prototyping experts improve a language-learning prototype that adheres to our framework‚Äôs principles. We then simulated typical user feedback and observed how experts addressed the requests.\nCurious to see these live-prototyping sessions decoded? Head over to ‚ÄúThe AI of Oz‚Äù to check out our framework diagram, user reflections on what worked (and what didn‚Äôt), and the next-generation toolkit we‚Äôre building to make in-session design both practical and inspiring.\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"14 May 2025","externalUrl":null,"permalink":"/my-work/posts/1747834902943-ucd-framework/","section":"","summary":"","title":"On-the-Fly AI Prototyping: Revolutionizing UX Testing","type":"posts"},{"content":"","date":"14 May 2025","externalUrl":null,"permalink":"/my-work/tags/user-centered-design/","section":"Tags","summary":"","title":"User-Centered Design","type":"tags"},{"content":"","date":"14 May 2025","externalUrl":null,"permalink":"/my-work/tags/ux-testing/","section":"Tags","summary":"","title":"UX Testing","type":"tags"},{"content":"Photo by Clint Bustrillos on Unsplash\nIntroduction # Tabletop role-playing games (TTRPGs) have long held a special place in the hearts of storytellers, gamers, and fantasy lovers. It features a unique experience that blends structured rules with creative freedom, creating a shared universe where players and a Game Master (GM) create stories together. As new technology reshapes how we play, it is only a matter of time until generative artificial intelligence (AI) joins the party.\nWhen applied to TTRPGs, this tool can transform how games are prepared and played. By complementing human creativity, AI introduces a new era of dynamic and personalized storytelling.\nFrom Dice to Digital: A History of Play # TTRPGs began with pen and paper, dice, and raw imagination. Over time, players and GMs adopted digital tools into their preparation and gameplay. There are three parts to this transition:\nAnalog Origins\nEarly games of Dungeons \u0026amp; Dragons relied heavily on physical rulebooks, drawn maps, and group imagination. Online Platforms Emerge\nTools like Roll20 and D\u0026amp;D Beyond digitized many aspects of gameplay, allowing playgroups to connect virtually. Hybrid Playstyles\nToday, many campaigns combine analog charm with digital convenience, such as dynamic maps paired with physical dice. This gradual shift laid the foundation for integrating even more advanced tools like generative AI.\nImagination at the Core # Creativity is the beating heart of every role-playing game. It is what drives compelling narratives and introduces unique characters, which often serve as a reflection of our experiences. Unique to TTRPGs, creativity manifests in scenarios such as:\nCollaborative Storytelling\nThe storyline isn‚Äôt dictated‚Äîit‚Äôs negotiated by the table. The GM‚Äôs Role\nThe GM crafts the setting, controls the rhythm, and reacts to player unpredictability. Player-Driven Twists\nCharacters‚Äô decisions continually reshape the world and the narrative. The interactions between players and GMs make TTRPGs more than just games‚Äîthey are living stories that ebb and flow.\nWhere Creativity Gets Stuck # Despite their rich potential, traditional TTRPGs are not without friction. This friction can manifest from varied skill gaps among players, especially those not comfortable with improvising, to improv fatigue stemming from burnout due to creativity demands from players and GMs. A lack of structure or memory tools can also lead to unresolved plot holes or forgotten arcs. These challenges can compound on top of each other and deter players\u0026rsquo; creativity.\nThese challenges can be separated into two categories based on which aspect of the game they occur: preparation vs. gameplay challenges. Preparation challenges occur during the campaign or session planning stages of the game, while gameplay challenges occur during the sessions themselves. While there can be an overlap between the two categories, how we address these creative challenges can differ significantly by way of the interactions that are affected. These interactions can be seen through who is affected by these issues: with preparation often dealing with the self, while gameplay often dealing with the group and its dynamics.\nHow AI Fits at the Table # Generative AI has the potential to address these challenges by sharing the creative load. To understand its impact, it‚Äôs essential to know how it operates:\nHow It Works\nAI tools are trained on vast datasets to generate language, images, or ideas. Think ChatGPT writing NPC dialogue or Midjourney creating landscapes. AI Tools in TTRPGs\nSome popular applications include Dungeon Alchemist for map creation, GPT-based prompt generators, and various virtual assistants. The introduction of generative AI shifted its role from mere automation to true creative expansion‚Äîmuch like how Photoshop revolutionized digital art.\nBridging Skill Gaps with AI Tools # With the widespread use of text-based tools like ChatGPT and Gemini, GMs have started incorporating them into their digital ecosystems with varying levels of creative control. While traditional GMs tend to leave AI with logistical roles like scheduling sessions and creating outlines and summaries, others are open to letting AI take the creative reins by incorporating them in world-building and character creation. Common examples include creating a dungeon based on a core concept from the GM and letting AI suggest traps and puzzles, or creating factions based on an established deity from the world lore. Instead of replacing the GM, AI can enhance their imagination with varied levels of creative control.\nThe tool can also benefit players. Due to the nature of the player\u0026rsquo;s role within the story, they often focus heavily on the creation and development of their characters. AI provides solutions through character builders that can add depth to a concept or generate new ones from scratch. Personality quizzes and trait selectors are often used to make character creation faster while introducing some depth that the player can build upon. Large language models (LLMs) can also be tailored for this specific purpose through training with specialized datasets. Even with minimal prompting, a complex character idea can be generated that the player can shape into their own. This empowers new players to participate confidently and creatively while giving more veteran players new ideas to work with.\nLive Sessions, Real-Time Collaboration # One of the most exciting aspects of generative AI is its ability to adapt in real time during a gaming session. During sessions, it can help GMs and players adapt to unexpected turns, generate spontaneous content, and keep the story flowing without breaking immersion.\nInstant Descriptions\nGenerate vivid locales, NPCs, and items on the fly. Reactive World-Building\nAdjust crowd behavior, summon unexpected encounters, or introduce plot twists as players explore. Improvised Plot Hooks\nOffer side quests or character arcs that align with the established story. By responding instantly and intelligently, AI turns improvisation into true collaboration, keeping both GMs and players fully immersed.\nCreative Power vs. Creative Control # While generative AI can enhance storytelling, it also introduces risks that can undermine the core of TTRPGs if not handled carefully. When AI takes too much creative control, it can overshadow the GM‚Äôs vision and reduce player agency, making choices feel less meaningful. Improvised elements may not align with the campaign‚Äôs tone or continuity, and relying on AI for key moments can sap the spontaneity and emotional depth that make tabletop role-playing compelling in the first place.\nOutside the narrative, broader concerns like content ownership, data privacy, and algorithmic bias come into play. It\u0026rsquo;s often unclear who owns AI-generated material, especially when using proprietary platforms, and user inputs could be stored or repurposed without clear consent. If not properly monitored, AI tools can replicate harmful stereotypes embedded in their training data, affecting the inclusivity and integrity of the game. AI can be a powerful co-creator, but it demands a cautious and intentional approach.\nWhat Comes Next? A Creative Crossroads # Generative AI is opening new doors for creativity in TTRPGs, from rich world-building to real-time improvisation. But with these tools come important questions:\nHow do we keep storytelling spontaneous? How do we ensure AI enhances rather than directs the game? The challenge lies in using AI thoughtfully, as a creative partner rather than a narrative crutch. After all, while code may shape the tools, the heart of every TTRPG remains undeniably human. As we explore what‚Äôs possible, one question guides us:\nHow will you let generative AI enhance your next adventure?\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"13 May 2025","externalUrl":null,"permalink":"/my-work/posts/1747160072917-ai-in-creative-writing/","section":"","summary":"","title":"A New Era for Tabletop Role-Playing Games","type":"posts"},{"content":"","date":"13 May 2025","externalUrl":null,"permalink":"/my-work/tags/game-master-tools/","section":"Tags","summary":"","title":"Game Master Tools","type":"tags"},{"content":"","date":"13 May 2025","externalUrl":null,"permalink":"/my-work/tags/real-time-collaboration/","section":"Tags","summary":"","title":"Real-Time Collaboration","type":"tags"},{"content":"Photo by Nubelson Fernandes on Unsplash\nIntroduction # Have you ever glanced up from your screen after hours of back-to-back video calls and realized you feel more tense than when you started? In our hyperconnected world, endless notifications and marathon work sessions have become the norm, and stress seems to tag along for the ride. As we spend more time seated, glued to laptops or phones, that mental tension only grows; the ongoing shift towards digital sedentary lifestyles has increased stress in daily life and calls for innovative approaches to improve mental and physical health.\nTraditional relaxation techniques (think guided meditations, breathing apps, or quick stretch breaks) certainly help, but they often demand that you pause your workflow, switch contexts, or stare at yet another screen. In a world where multitasking rules, these methods can feel like just one more item on your to-do list. This tension between our need to stay productive and our need to unwind inspired us to look beyond visual and auditory cues, and to ask: what if you could slip into a calmer state without ever leaving your desk?\nAffective Haptics Meets Generative AI # Affective haptics focuses on using touch to impact your emotional state, while advances in generative AI produce dynamic, personalized soundscapes; together, they promise seamless, multisensory experiences that gently guide users into calm states without demanding visual attention or interrupting flow.\nTurning Touch into Emotion # Affective haptics is a growing field dedicated to designing systems that can evoke or modulate emotions through tactile stimuli, from gentle pulses to complex vibration patterns. Research on affective haptics has demonstrated that well-crafted haptic cues can reduce stress, enhance mood, and improve user engagement in virtual environments.\nThe Rise of Generative Soundscapes # Meanwhile, generative AI has revolutionized how we create and experience audio: platforms like Endel partner with Universal Music Group to produce on-the-fly soundscapes tailored to factors like time of day and heart rate, helping listeners relax or focus without repetitive loops. Even artists like Grimes have explored AI-driven lullabies that adapt in real time to user data, showcasing the technology‚Äôs potential for personalized well-being experiences.\nA New Frontier: Resonant Relaxation # At its core, Resonant Relaxation is about harnessing subtle haptic pulses and AI-generated audio to nudge you toward a calmer headspace without having to step away from your desk. Imagine a lightweight wristband or neckband that doesn‚Äôt just buzz, but breathes with you, guiding your rhythm toward a more relaxed state.\nUnder the hood, our prototype is a React-based web app that leans on GPT-4o to craft MIDI compositions from simple prompts. Those MIDI files are then turned into real-time waveforms via Tone.js and fed into voice-coil actuators embedded in wearable patches. What you feel is two layers working in concert:\nA breathing-paced hum, starting just above your natural breath rate and decelerating to gently coax you into slower, deeper breathing AI-generated ‚Äúsparkles‚Äù, melodies aligned to the baseline frequency that keep the sensation novel and engaging In our first round of user tests with three participants tackling different sedentary tasks, everyone reported feeling noticeably calmer, and most loved the textured ‚Äúsparkle‚Äù layer over a plain hum.\nJoin Us on Our Journey! # Resonant Relaxation represents our first step toward blending AI-generated soundscapes with procedurally crafted haptic patterns right at your desk. In our paper, you‚Äôll find a detailed walk-through of our system architecture, from the ChatGPT-driven MIDI generation to the real-time Tone.js rendering and voice-coil actuation, along with rich code snippets and visualizations. We also dive deeper into our initial qualitative study, where participants across varied sedentary tasks reported feeling measurably more relaxed, and unanimously loved the layered ‚Äúsparkle‚Äù haptics over a simple baseline. Whether you‚Äôre a haptic designer, developer, or researcher, our open-source prototype is yours to explore and build upon on GitHub.\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"24 June 2024","externalUrl":null,"permalink":"/my-work/posts/1747834927981-haptics/","section":"","summary":"","title":"Deskside Calm: Exploring AI-Driven Haptic Wellness","type":"posts"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/my-work/tags/haptics/","section":"Tags","summary":"","title":"Haptics","type":"tags"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/my-work/tags/ux/","section":"Tags","summary":"","title":"UX","type":"tags"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/my-work/tags/wearables/","section":"Tags","summary":"","title":"Wearables","type":"tags"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/my-work/tags/wellness/","section":"Tags","summary":"","title":"Wellness","type":"tags"},{"content":"","date":"9 July 2023","externalUrl":null,"permalink":"/my-work/series/ai-for-scenario-based-learning/","section":"Series","summary":"","title":"AI for Scenario-Based Learning","type":"series"},{"content":"","date":"9 July 2023","externalUrl":null,"permalink":"/my-work/tags/ai-language-learning/","section":"Tags","summary":"","title":"AI Language Learning","type":"tags"},{"content":"","date":"9 July 2023","externalUrl":null,"permalink":"/my-work/tags/design-guidelines/","section":"Tags","summary":"","title":"Design Guidelines","type":"tags"},{"content":"Photo by Markus Winkler on Unsplash\nIntroduction # Generative AI has opened new frontiers for Intelligent Computer-Assisted Language Learning (ICALL), offering the ability to produce vast quantities of contextually relevant, grammatically correct practice material on demand. By leveraging large-scale language models, educators can craft scenarios that adapt to real-world communicative goals, increasing learner motivation and authenticity of practice. Contemporary research highlights the potential of these tools to democratize language education through dynamic content generation and personalized feedback loops.\nTo translate this potential into a usable tool, we embarked on three weekly user-testing sessions with German learners, following a test-talk-improve cycle. Each round revealed critical insights:\nFrom the need for forgiving speech-to-text and dynamic dialogue in the first iteration. To interface polish and in-context corrections in the second. Finally, to features supporting long-term engagement in the third. However, these iterations gave us more than just feedback on our tool. Our journey gave us a glimpse into the minds of language learners and their typical ways of working. Remember to check out the tool in our Github!\nNow, with dozens of interviews, hours of observation, and a clear roadmap of recurring requests and pain points, we‚Äôre ready to share a set of practical design guidelines. In this article, you‚Äôll learn how to craft prompts that give your AI the context it needs, build adaptivity that matches each learner‚Äôs skill level, and shape a user experience that is familiar, forgiving, and even fun. Whether you‚Äôre wiring up speech and vision models or sketching out your next language-learning app, these guidelines will help you turn powerful AI into a truly human-centered tool.\nDesign Guidelines: What Makes an AI Language Tool Work? # After three rounds of testing, dozens of interviews, and hours of observation, we started seeing recurring issues, feature requests, and user behaviors that gave us a clearer picture of what works (and what doesn‚Äôt) in an AI-powered language learning tool.\nFrom those insights, we developed a set of practical design guidelines grounded in real user feedback and tested through iteration. They address three key areas: how the AI is prompted, how the tool supports language learning, and how the overall user experience comes together.\nContext Is Everything # Let‚Äôs start with the heart of the tool: the generative AI itself.\nOne of the most consistent issues users flagged was that the AI sometimes felt too generic and flat. The scenarios didn‚Äôt always match expectations, and the responses didn‚Äôt feel personal. We realized that prompting matters a lot in how the AI behaves.\nThe system needs detailed, meaningful context to generate more relevant, human-like interactions. Give users a way to customize the AI or choose from tailored scenario options. When you‚Äôre juggling multiple models (e.g., one for speech recognition, another for visuals), maintain consistency in prompt structure. A useful strategy: have a central model like GPT-4 handle prompt generation for all sub-models to maintain a consistent tone, intent, and structure. Bottom line: You get out what you put in. Better prompts = better conversations.\nAdapt, Don‚Äôt Overwhelm # No two learners are alike, and the tool needs to reflect that.\nOne of the biggest opportunities we saw was around adaptivity. Users wanted the challenge level of conversations to match their current proficiency, not some fixed standard.\nImplement an adaptive difficulty system that adjusts grammar, vocabulary, and scenario complexity over time. Provide a user-controlled toggle so learners can set their own challenge level, balancing personalization with autonomy. For translation support, less is more: most participants preferred quick lookups for individual words or short phrases rather than full-sentence translations. Be Familiar, Forgiving, and Fun # Even the smartest AI won‚Äôt help much if the interface feels clunky or confusing. Thoughtful UX design makes all the difference.\nLeverage familiar structures like messaging apps: clear message bubbles, intuitive icons, and responsive layouts that users already understand. Offer manual speech control (press-to-talk) so users can pause, think, and then speak to boost learners\u0026rsquo; comfort and confidence. Include a ‚Äúhover to translate‚Äù feature (inspired by DeepL and Google Translate) for quick, inline word lookups without breaking the flow. These design choices should help reduce friction and build confidence to foster an experience that feels more like learning with a helpful guide and less like wrestling with a chatbot.\nConclusion: From Prototype to Possibility # This project began as a question: how can generative AI make language learning more personal, immersive, and approachable? Through three iterations, we explored that question with real learners. While the prototype is far from perfect, the insights we gained have been invaluable.\nWe saw firsthand how flexible input methods, scenario-based conversations, and AI-powered feedback can support more confident and creative language practice. At the same time, we encountered the familiar challenges of learner motivation, limited emotional depth in AI, and the need for more intuitive, engaging design.\nThe design guidelines we‚Äôve shared are not just reflections of what we built. They\u0026rsquo;re a foundation for what comes next.\nLooking forward, we hope this work serves as a launchpad for new ideas in AI-assisted language learning and beyond. Whether applied to storytelling, game design, or live educational prototyping, the principles here can inform the next generation of tools that put learners at the center.\nThis is just the beginning.\nRemember to check out the tool in our Github!\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"9 July 2023","externalUrl":null,"permalink":"/my-work/posts/1748174596182-sla-findings/","section":"","summary":"","title":"Design Guidelines: What Makes an AI Language Tool Work?","type":"posts"},{"content":"","date":"9 July 2023","externalUrl":null,"permalink":"/my-work/tags/icall/","section":"Tags","summary":"","title":"ICALL","type":"tags"},{"content":"","date":"9 July 2023","externalUrl":null,"permalink":"/my-work/tags/scenario-based-learning/","section":"Tags","summary":"","title":"Scenario-Based Learning","type":"tags"},{"content":"","date":"8 July 2023","externalUrl":null,"permalink":"/my-work/tags/findings/","section":"Tags","summary":"","title":"Findings","type":"tags"},{"content":"Photo by UX Indonesia on Unsplash\nIntroduction # When we first set out to design a generative AI-powered language learning tool, our goal wasn‚Äôt just to build something cool with using multiple AI modules. We wanted to create something that helps people improve at speaking a new language in a way that feels natural and maybe even a little fun.\nSo, we built a prototype. We then handed it over to a group of language learners to see what worked, what didn‚Äôt, and what still needed improvement. Instead of doing one big test, we ran three iterative sessions. Why? Because learning (and designing for learning) is never a straight line. It‚Äôs messy, layered, and constantly evolving.\nIn each round, we listened closely to what participants said (and didn‚Äôt say), how they used the tool, where they got stuck, and what sparked their curiosity. Their feedback helped shape a better prototype and form a deeper understanding of what learners want when using AI to practice a language.\nThis article covers what we found along the way and what aspects of the tool needed improvements. Whether you‚Äôre an educator, a developer, or just curious about how AI can help us learn better, I hope these insights give you a window into making a digital language partner feel like it belongs in your life.\nOur Design Journey: Iterations Incoming! # To bring you up to speed, our testing process was split into three weekly feedback sessions, each building on the last. We brought in real German language learners to try out the prototype, share their thoughts, and help us shape it into something more useful and intuitive.\nEach session followed a simple rhythm: test, talk, improve. Participants explored the tool and shared their experiences through interviews and creative feedback exercises. After each round, we made focused updates based on what users wanted most and what we could realistically implement in time.\nThis iterative setup allowed us to gather deeper insights than a one-off test ever could. By the third session, users reflected on its potential and how they could implement a similar tool in their typical setups. And that‚Äôs where the most valuable feedback came from.\nFirst Iteration: A Promising Start # When we launched our first testing session, we weren‚Äôt sure what to expect but were eager to see how learners would respond to the early version of our prototype. Thankfully, they didn‚Äôt hold back.\nFirst iteration of the prototype showing the caf√© roleplay scenario with AI conversational agent and dynamic background Right off the bat, participants appreciated the flexibility in choosing different scenarios and the option to switch between typing and speaking. The voice recording feature, in particular, stood out. For many, it felt like a low-pressure way to practice speaking without worrying about making mistakes in front of others. One user even mentioned that talking to an AI felt less intimidating than speaking in class.\nWhisper (the speech-to-text engine we used) earned some unexpected praise. It often glossed over small spelling mistakes in transcriptions, which had a surprising side effect: learners felt more confident trying out complex vocabulary and sentence structures. When the tool didn‚Äôt penalize minor errors, they took more risks. This is exactly the kind of learning behavior we want to encourage.\nThat said, the first version of the prototype had its fair share of rough edges. Learners noted that the interface focused too much on text input, with little feedback or guidance to help them get started. The robotic voice used for text-to-speech made conversations feel stiff and unnatural. They also critiqued the visuals, which failed to immerse our learners.\nOur testers also felt the AI was too passive during conversations. Too often, they were left carrying the dialogue with minimal input from the virtual partner. Their feedback was clear: the tool needed to feel more like a real conversation and less like typing into a form. From that first round, a few key ideas started to emerge:\nMore dynamic AI dialogue Clearer onboarding and feedback Larger chat window Adjustable language complexity ‚ÄúHover to translate‚Äù for immediate word help We had our work cut out for us: a solid start that proves our concept for a scenario-based ICALL app, but with a handful of high-priority improvements ahead.\nSecond Iteration: Sharpening the Experience # Equipped with feedback from the first round, we went back to the drawing board to come up with a more polished version of the prototype. This second iteration was about smoothing the rough edges and making the experience feel more like a real language-learning tool, not just a tech demo.\nSecond iteration of the prototype showing the bakery roleplay with a refined UI: larger chat window, prominent microphone icon, and decoupled, faster image generation One of our first moves was to revamp the interface:\nBigger text output box and a bolder microphone icon to nudge users toward the speaking mode they favored. Decoupled dialogue output from image generation, resulting in noticeably faster response times. Under the hood, we also replaced gTTS with ElevenLabs Voice AI for far more natural-sounding speech. We hesitated at first, but repeated comments on the old audio‚Äôs uncanniness convinced us this change was essential.\nNext, we optimized our prompts for both Stable Diffusion and GPT-4. By adding a rule to center a character in each image, we gave learners a clear visual partner. And by tweaking the AI‚Äôs dialogue to be shorter and end with questions, conversations felt more dynamic and human.\nWe also introduced:\nVisual language correction for on-screen grammar and vocabulary hints Subtle audio feedback to reinforce progress and make the tool feel truly responsive Although our planned translation feature was postponed, participants loved the new conversation history panel, and many said the language corrections made the app feel like a real learning environment.\nA clear theme emerged: users wanted AI responses that matched their proficiency level. Some found the tool too advanced, others too simple. This insight planted the seed for our next big feature: adaptive AI responses tuned to each learner‚Äôs skill.\nThe second iteration was a major leap forward. The prototype felt faster, smarter, and most importantly, more usable.\nThird Iteration: Forward Thinking # By the time we reached our third and final iteration, the prototype had come a long way. Aside from fixing bugs or tweaking features, this round was also about asking bigger questions: How well does the tool support learners in the long term? and What should come next?\nThird iteration of the prototype showing the romantic restaurant roleplay with portrait layout, click to translate feature, expanded chat area, and on-demand translation panel We started by refreshing the interface once again. The text output area was expanded, and we switched to a portrait-oriented image layout that placed more visual emphasis on the scenario, another step we took towards better learner immersion.\nWe also added a highly requested feature: click-to-translate! Powered by the DeepL API, this let learners translate full sentences in the chat at a single tap. While participants loved the convenience, several noted they‚Äôd actually prefer translating individual words during active practice.\nBased on feedback, the new UI landed well as learners appreciated the cleaner layout, extra icons, and expanded chat space. Still, they spotted areas for polish:\nClearer sender distinction between user and AI messages A more modern, app-like visual style Filling the startup screen‚Äôs white space with conversation history Our scenario visuals also improved in clarity and relevance, but users craved even more engagement. Ideas included:\nAnimated avatars or expressive feedback (e.g., changing facial expressions) Deeper AI ‚Äúpresence‚Äù through local memory or emotional cues That didn‚Äôt stop them from dreaming up bold next steps:\nGamification features to boost motivation Improved onboarding for first-time users Customizable scenarios tailored to individual goals Vocabulary suggestions to bridge learning gaps This final round made one thing clear: while the core of the tool is solid, there‚Äôs a real opportunity to build something even more personalized, engaging, and emotionally intelligent. Thanks to our participants‚Äô thoughtful feedback, we now have a clear roadmap for making it happen.\nWhat Did We Learn? # Throughout all three iterations, one thing became increasingly clear: how people interact with the tool matters as much as what the tool can do.\nText vs. Voice: Different Paths, Same Goal # When it came to communication style, participants naturally split into two camps:\nTyping enthusiasts Speaking aficionados Each had its strengths, but speech-to-text (STT) emerged as a sleeper hit. Thanks to Whisper, even slightly mispronounced words were transcribed accurately, giving learners a confidence boost to experiment with new vocabulary. Better inputs led to richer, more coherent outputs from GPT-4.\nThe takeaway? Giving learners flexible and forgiving ways to communicate helps lower the barrier to participation and opens up space for real growth. However, this is a double-edged sword, since proper communication requires proper pronunciation of words and phrases, which the tool cannot detect currently.\nWhy Scenario-Based Practice Matters # Across the board, users leaned into scenario-based learning. They valued speaking through a scene instead of just typing, noting the record function created a natural, low-pressure environment.\n‚ÄúIt felt less intimidating than speaking in a classroom.‚Äù\nWithout classmates to impress or teachers to interrupt, learners felt free to shape conversations. This judgment-free space translated into real confidence and motivation.\nThe Limits of a Standalone Experience # Not every hurdle could be cleared. As novelty wore off, two challenges emerged:\nMotivation: While some used the tool to prep for exams, many struggled to stay consistent on their own. Maybe integrating gamification techniques, like reminders, rewards, or progress tracking, could encourage regular use.\nAI Personality: Learners described the chatbot as ‚Äúfaceless‚Äù and lacking emotional depth, memory, or character. A potential solution: add intuitive design elements, clearer guidance, or even a bit of personality (avatars, emotional cues) to make the tool feel alive.\nThese insights confirmed that a great AI tutor needs both technical power and a human touch to truly engage learners.\nWe Learned, Now What? # After three quick rounds of testing, we learned that user feedback is the fastest path from prototype to a helpful language partner. Letting learners switch between typing and speaking and framing practice as mini-scenarios made them more confident and curious. Speeding up responses, adding on-screen hints, and tuning speech quality showed that a tool‚Äôs polish matters as much as its AI core. Yet we also saw that without motivation boosters or a bit of personality, language learners quickly lost the novelty factor of the tool.\nNext, we‚Äôll turn these lessons into concrete design guidelines for your generative AI tool. In the next article, you‚Äôll discover how to pick and combine speech, vision, and language modules, structure user flows that keep learners coming back, and sprinkle in gamification or avatars to make each session feel alive!\nRemember to check out the tool in our Github!\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"8 July 2023","externalUrl":null,"permalink":"/my-work/posts/1748099731762-sla-findings/","section":"","summary":"","title":"Generative AI in Language Learning: User Testing Findings","type":"posts"},{"content":"","date":"8 July 2023","externalUrl":null,"permalink":"/my-work/tags/ux-design/","section":"Tags","summary":"","title":"UX Design","type":"tags"},{"content":"","date":"7 July 2023","externalUrl":null,"permalink":"/my-work/tags/design/","section":"Tags","summary":"","title":"Design","type":"tags"},{"content":"Photo by Studio Crevettes on Unsplash\nIntroduction # Learning a new language is more than just memorizing vocabulary and grammar rules. It‚Äôs about connecting with people, understanding different cultures, and expressing oneself in new ways. However, traditional language learning methods often fall short, especially when they can‚Äôt adapt to individual learning styles or provide real-life conversational practice.\nEnter Artificial Intelligence (AI). Recent advancements in AI, particularly in Natural Language Processing (NLP), have opened up exciting possibilities in language education. One such innovation is Intelligent Computer-Assisted Language Learning (ICALL), which uses AI to create personalized and adaptive learning experiences. These systems can analyze how learners interact with language, identify their strengths and weaknesses, and tailor lessons to fit their needs.\nBut we can go even further. As I covered in my previous article, generative AI models can engage learners in dynamic conversations, provide instant feedback, and simulate real-world scenarios. Imagine practicing a job interview in your target language with an AI that responds naturally or exploring a virtual marketplace where you can haggle over prices from the comfort of your home.\nOur research aims to bridge this gap by exploring how generative AI can create engaging, personalized, and context-rich language learning experiences. By integrating advanced AI technologies with proven language learning strategies, we hope to make language education more accessible, effective, and enjoyable for all learners.\nWhat We Set Out to Discover # When learning a new language, one size doesn‚Äôt fit all. People bring different experiences, personalities, and learning styles into the process, which is especially true for second language learners. So, we asked ourselves:\nHow can generative AI create personalized, scenario-based learning experiences that tap into learners‚Äô creativity?\nRather than just building another language app, we want to design something that adapts to the individual. We want users to understand that language learning is as much about context and confidence as grammar and vocabulary.\nTo answer this, we reviewed the current state of ICALL tools, studied their strengths, and pinpointed where they fall short in personalization and immersion. Then, we explored how modern generative AI technologies could fill those gaps.\nDesigning for Real Learners # It‚Äôs one thing to imagine a smarter learning system, but another to build it in a way that truly works for people. That‚Äôs why we took a user-centered approach.\nWe envisioned an interconnected system of AI modules working together to create dynamic roleplay scenarios. These modules weren‚Äôt just randomly assembled, they\u0026rsquo;re based on established design principles from language education research, combined with real-world input from learners.\nTo test our ideas, we brought in language learners from diverse backgrounds who were already on their second-language learning journeys. Our team facilitated a series of hands-on user experience (UX) sessions. These sessions weren‚Äôt just about testing the tool, they were about discovering how people interact with it, what works, what doesn‚Äôt, and how to make the experience more intuitive, engaging, and effective.\nMeet the Learners # We recruited five participants actively learning German as a second language. These weren‚Äôt complete beginners, but they weren‚Äôt fluent either. Their skills ranged from A1 to B1 (beginner to lower-intermediate). All had studied German for at least six months and were eager to improve their conversational skills. Most importantly, they represented our target users, making their feedback essential.\nHow We Ran the Sessions # Instead of a single big test, we opted for an iterative approach. Over three weeks, we held three feedback sessions with all five participants. Each session lasted about an hour, giving us time to refine our prototype step by step.\nHands-on Testing\nParticipants interacted with the prototype while we observed how they navigated the interface, reacted to conversations, and engaged with visual content.\nDeep-Dive Conversations\nAfter testing, we conducted semi-structured interviews to explore their learning experiences, likes and dislikes, and improvement ideas. We focused on conversation quality, interface design, generated images, and overall usability.\nWe also used generative feedback methods like group brainstorming and quick sketching exercises. These helped participants clarify their ideas for features and layouts, giving us valuable insights into their vision for an ideal language-learning tool.\nWhy Iteration Mattered # Each session built on the last. As learners spent more time with the tool, they offered richer feedback. This iterative format allowed us to evolve the design thoughtfully and responsively.\nAfter each session, we reviewed the feedback and drafted changes. We prioritized updates based on:\nFrequency ‚Äì How often an issue was mentioned Importance ‚Äì How crucial it seemed to participants Feasibility ‚Äì How practical it was to implement This ensured our updates served the whole group and moved the project forward in a balanced way.\nBuilding the Prototype # First iteration of the prototype showing the caf√© roleplay scenario with AI conversational agent and dynamic background To support an iterative, feedback-driven design, we built a modular system with four key components:\nA simple and adaptable user interface A tool for converting spoken language to text A system for realistic, AI-powered conversation An engine for creating images based on conversation context These pieces had to work together seamlessly and be easy to update between sessions.\nThe Tools Behind the Scenes # Pygame: Chosen for its flexibility and ease of UI tweaks. Whisper: For fast, multi-language speech-to-text. gTTS: For quick, cost-free text-to-speech. GPT-4: Driving the conversation with human-like responses. Stable Diffusion: Providing high-quality, locally-runnable image generation. How the Prototype Worked # Start the Scenario: The learner types or speaks their first input. Whisper transcribes speech, and GPT-4 interprets it, setting the conversation context.\nGenerate the Visual: A prompt combining user input and a predefined scene description is sent to Stable Diffusion, which updates the app‚Äôs background image.\nInteractive Loop:\nLearner responds (text or speech) GPT-4 replies in the textbox gTTS reads the response aloud Stable Diffusion updates the scene if needed What‚Äôs Next: From Prototype to Practice # With our prototype up and running, we‚Äôve laid the groundwork for a more personalized and immersive approach to second language learning. By integrating generative AI into scenario-based learning, we‚Äôve opened new avenues for learners to engage with language in context-rich environments.\nBut building the prototype was just the beginning. The real insights emerged as we tested and refined the system with actual learners. Their experiences, challenges, and feedback have been invaluable in shaping the tool to meet their needs better.\nIn our next article, we‚Äôll look into:\nUser Feedback: What did learners think? We‚Äôll share their experiences and the impact on their language acquisition journey. Lessons Learned: From successes to setbacks, we\u0026rsquo;ll discuss what worked, what didn\u0026rsquo;t, and how these insights can inform future developments. Remember to check out the tool in our Github!\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"7 July 2023","externalUrl":null,"permalink":"/my-work/posts/1748091371063-icall-method/","section":"","summary":"","title":"Designing an AI-Driven Language Learning Tool","type":"posts"},{"content":"","date":"7 July 2023","externalUrl":null,"permalink":"/my-work/tags/prototype/","section":"Tags","summary":"","title":"Prototype","type":"tags"},{"content":"","date":"6 July 2023","externalUrl":null,"permalink":"/my-work/tags/chatbots/","section":"Tags","summary":"","title":"Chatbots","type":"tags"},{"content":"Photo by sean Kong on Unsplash\n‚ÄúImagine a tool that lets you practice for a job interview in Spanish and gives rich feedback akin to a personal tutor, anytime you want! How would such a tool look?‚Äù\nA Deeper Look at CALL and Early ICALL # Computers entered language teaching in the 1960s with simple drill-and-practice programs: fill-in-the-blank exercises that offered immediate correct/incorrect feedback. This Behaviourist CALL phase laid the groundwork for using technology in the classroom. By the 1990s, Integrative CALL harnessed the internet and multimedia to provide authentic content like videos, audio, and text to enhance learner motivation and exposure to real-world language. Yet, personalization remained minimal.\nThe early 2000s saw the birth of ICALL, where natural language processing (NLP) enabled more intelligent feedback. ICALL systems could automatically correct grammar, suggest vocabulary, and generate simple exercise variations. Despite these advances, interactions were mostly rule-based or template-driven, and true open-ended dialogue was still out of reach.\nGenerative AI Enters the Chat # The introduction of Transformer-based models like GPT-3 in 2020 and services like ChatGPT, brought a leap forward. These models generate coherent, context-aware language, that allows:\nLonger, more natural dialogues On-demand explanations and exercises Adaptive language complexity Since ChatGPT uses natural language to communicate, language learning was one of the key application areas focused on. However, its application is largely still being experimented on, with three leading the charge:\nMeet Your AI Tutor # A 2024 study by Panagiotidis showed that LLM-powered chatbots enhance learner engagement by providing instant, personalized feedback. Modern AI tutors blend flexibility with guidance:\nChatGPT: Offers conversation practice, grammar corrections, and explanations on any topic. Duolingo Max: Uses GPT-4 to power role-plays and step-by-step grammar coaching. Speak: Focuses on spoken practice that listens to your voice, then provides pronunciation and grammar feedback. These tutors adapt to your level and interests, giving you a judgment-free space to practice. However, chatbots offer little to no features for learners who prefer an immersive experience. This is particularly troublesome for learners who would much rather learn through practice. Thankfully, another application targets that specific problem.\nScenario-Based Learning in a New Light # Scenario-based language learning immerses learners in realistic conversations, a key method for transferring classroom knowledge to real-world use. Traditionally, role-plays and simulations required extensive scripting, but generative AI changes that:\n‚ÄúLet‚Äôs role-play a hotel check-in in French.‚Äù\nWith generative AI, learners can engage in open-ended role-play conversations where the AI assumes a role in the scenario and responds unpredictably yet appropriately. This technique is already being applied to certain services and local setups:\nPi: An empathetic bot that can impersonate countless roles, from car dealers to tour guides. NotebookLM + ChatGPT: One generates scenario prompts; the other conducts interactive mock interviews. Character.AI: Create custom characters to practice specific contexts and scenarios. This flexibility fills a critical gap: authentic, contextualized practice without the content-creation headache. However, it is not uncommon to see scenario-based learning as a gimmick that is used sparingly. Since any scenario can be generated, it lacks a way to get the user to imagine scenarios or motivate them to learn. Thus, a third application area is introduced.\nGamification Gets Smarter # In 2025, DaCosta‚Äôs work demonstrated how adding ChatGPT to text-adventure games creates immersive language quests, letting learners explore and interact naturally as they play. The flexibility afforded by generative AI helps revitalize new and existing language-learning games:\nInteractive stories that adapt to your choices to further enhance immersion. Custom challenges emphasize your target grammar and vocabulary, keeping your level in check. Non-playable Characters (NPCs) respond to free-form input instead of pre-determined selections. This dynamic content keeps you engaged and motivated without overwhelming you. With generative AI, a learner could potentially craft their learning regimen based on their commitment and effort goals.\nBut, Why do AI-Powered Scenarios Matter? # Traditional ICALL tools often fall short on authenticity, adaptivity, and engagement. Generative scenario-based learning addresses these longstanding ICALL gaps:\nPersonalization: Scenarios adjust to your level and interests in real-time. Authenticity: Practice real-world tasks like job interviews, doctor visits, negotiations. Instant feedback: AI highlights errors and suggests better phrasing. Scalability: Instructors describe a scene; AI builds it. Engagement: Endless variations keep motivation high. The goal of using these tools is to move past memorizing phrases, and start learning to think in the language by yourself!\nWrapping Up and What\u0026rsquo;s Next # We‚Äôre at the dawn of a new era in Second Language Acquisition where AI-driven, scenario-based ICALL systems can provide truly immersive, personalized, and engaging practice. As platforms evolve, expect to see even smarter applications of generative AI that immerse you in language learning. However, the question still remains:\n\u0026ldquo;How would such a tool look?\u0026rdquo;\nI got you covered! In this new series of articles, I\u0026rsquo;ll go over a research project I did with my colleagues at the University of Salzburg on Utilizing Generative AI for Scenario-Based Second Language Acquisition! In the next section, I\u0026rsquo;ll explain how we designed a tool with second-language learners in mind and how we iterated and improved it over time!\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"6 July 2023","externalUrl":null,"permalink":"/my-work/posts/1748010464372-genai-icall/","section":"","summary":"","title":"From Drills to Dialogues: A New Era for Language Learners","type":"posts"},{"content":"","date":"6 July 2023","externalUrl":null,"permalink":"/my-work/tags/gamification/","section":"Tags","summary":"","title":"Gamification","type":"tags"},{"content":" ‚ú® Welcome to Valeria # Where magic and technology collide, and legends come to life. Valeria is a realm of stark contrasts: from the merchant spires of Maleketh to Felgrand‚Äôs steam-driven alleys, from the icy ramparts of Timmaeus to the floating canals of Boljaw, and the rugged frontier of Yarlford. Here, powerful alliances‚Äîlike the noble Purple Dragon Knights, the cunning Syndicates, and the wealth-driven High Families of Maleketh‚Äîshape politics and peril. Brave adventurers will forge bonds with the valiant Talon Hunters or navigate the hidden agendas of Felgrand‚Äôs underworld.\nBeneath these mortal struggles lies the Valerian Pantheon, a tapestry of divine and primordial beings. Stand before Seraphim Archangel‚Äôs radiant glory, tremble at Arkus the Horned‚Äôs infernal might, or seek the fragile mercy of Solomon As-Sajdah, the Grim Reaper of souls. From the legendary dragon Reigadyrth to the enigmatic Lady Fortuna, each deity weaves fate and destiny into the fabric of the world.\nWhether you‚Äôre a Game Master crafting epic campaigns or a player seeking heroic deeds, this compendium is your gateway to the wonders and dangers of Valeria. Explore alliances, delve into the pantheon, and prepare your story in a land where every choice echoes through myth and history.\n","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/worlds/","section":"","summary":"","title":"","type":"worlds"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/cities/","section":"Tags","summary":"","title":"Cities","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/dnd/","section":"Tags","summary":"","title":"DnD","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/families/","section":"Tags","summary":"","title":"Families","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/fantasy/","section":"Tags","summary":"","title":"Fantasy","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/homebrew/","section":"Tags","summary":"","title":"Homebrew","type":"tags"},{"content":"Image generated by DALL¬∑E 3 via ChatGPT\nIntroduction # In the land of Valeria, magic and technology collide in a battle for supremacy. The realm is divided into two contrasting regions‚Äîwest and east‚Äîwhere vast countryside and bustling cities coexist. Valeria‚Äôs five major cities each have unique identities and challenges:\nMaleketh Felgrand Timmaeus Boljaw Yarlford As you journey through Valeria, you‚Äôll encounter powerful wizards, cunning thieves, ferocious dragons, and mythical beasts. Forge alliances, make enemies, and uncover hidden secrets and treasures in this land of contrasts.\nMajor Cities # Maleketh # Nestled in the prosperous northeast, Maleketh is Valeria‚Äôs merchant capital. Its spires and grand marketplaces hum with trade, and the city‚Äôs fortunes rest on four High Families:\nBarlowe: Controls transportation across the realm Megadome: Built and maintains the city‚Äôs infrastructure Evermont: Oversees the distribution of wine and spirits Saka: Owns the food and hospitality industries At the city‚Äôs heart stands Mount Doloro, the tallest peak in Valeria, said to house the Dwarven King and his sons in hidden forges. Nearby, the Great Colosseum‚Äînamed for the legendary warrior Maleketh Stallion‚Äîhosts fierce battles between gladiators and beasts.\nDespite its wealth, Maleketh teems with danger. Criminal networks and smugglers prey on the unwary. The Purple Dragon Knights maintain order, but the shadowy Syndicates constantly test their authority. Venture through crowded streets at your own risk‚Äîsecrets in Maleketh can be deadly.\nFelgrand # Located at the crossroads of Valeria‚Äôs regions, Felgrand is a steampunk metropolis ruled by the criminal Syndicates. Innovation thrives so long as profits flow, and the skyline bristles with airships and steam-powered vehicles.\nSyndicates: Loose alliances of rival crime lords Black Market: Hidden beneath the streets; goods and services of dubious legality Newcomers risk robbery or worse in Felgrand‚Äôs alleys, but savvy traders can strike it rich. The city‚Äôs thrilling unpredictability makes it both dangerous and irresistible.\nTimmaeus # In the frozen northwest lies Timmaeus, a city of stone walls and icy winds. Its people are hardy, bound by tradition and protected by the Purple Dragon Knights, who maintain their headquarters here.\nSkathi Peak: Valeria‚Äôs second-highest mountain, home to the fierce Mighty Frost tribe College of Timmaeus: Premier institution for magical study Though knowledge and magic flourish, dark forces and savage beasts lurk beyond the walls. Only the resourceful survive the frigid wastes.\nBoljaw # Boljaw, the City of Canals, spans the tropical marshes of the southwest. Boats, not carts, ply its waterways, and every district blends magic with engineering marvels.\nOld Quarter\nNarrow, twisting canals and leaning buildings A maze only locals can navigate New Quarter\nBroad waterways and towering mansions Home to the wealthy elite Docklands\nBustling ports and merchant ships Beware of cutpurses and smugglers The Palace of Boljaw overlooks it all, where the Duke and council rule. Hidden treasures and lost artifacts await those daring enough to brave the canals.\nYarlford # In the southeastern wilderness lies Yarlford, a rugged countryside governed by Mayor Cleopatra Cretari, a tiefling descended from famed hunters. The region is dotted with cozy cottages and lively markets, but life here demands strength and resilience.\nMayor Cleopatra Cretari: Crimson-skinned leader from a line of hunters Wildlife: Deer and rabbits; wolves, trolls, and other predators Terrain Hazards: Treacherous forests, fierce storms, and bandit ambushes Under Mayor Cretari‚Äôs leadership, Yarlford‚Äôs hardy folk strive to thrive, honoring their ancestors‚Äô legacy in a land as beautiful as it is unforgiving.\n","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/worlds/1747762655679-valeria-main/","section":"","summary":"","title":"Journey Through Valeria: Five Cities of Magic and Innovation","type":"worlds"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/knights/","section":"Tags","summary":"","title":"Knights","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/mage-punk/","section":"Tags","summary":"","title":"Mage-Punk","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/pantheon/","section":"Tags","summary":"","title":"Pantheon","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/syndicates/","section":"Tags","summary":"","title":"Syndicates","type":"tags"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/valeria/","section":"Tags","summary":"","title":"Valeria","type":"tags"},{"content":"Image generated by DALL¬∑E 3 via ChatGPT\nAlliances # Valeria‚Äôs stability hinges on powerful bonds between its defenders, rulers, and underworld powers. From the chivalric Purple Dragon Knights, sworn to uphold justice in every city, to the shadowy Syndicates of Felgrand, and the influential High Families of Maleketh, each alliance shapes the political and social landscape. In the border town of Taloncroft, the Talon Hunters stand as an independent force, protecting the frontier from beasts and dark magic. Together, these factions uphold‚Äîor threaten‚Äîthe delicate balance of power across Valeria.\nThe Purple Dragon Knights The Syndicates High Families of Maleketh The Hunting Guild The Purple Dragon Knights # In the kingdom of Valeria, the noble order of the Purple Dragon Knights was founded centuries ago in honor of the dragon Reigedyrth, who aided Queen Valeria in unifying the realm. Renowned for bravery, honor, and loyalty, they uphold peace and security in Valeria‚Äôs most important cities.\nOrder Structure # Knight Captain: Commands each city brigade Sections (per brigade): Knight Lieutenant Marshal-at-Arms Knight Strategist Maleketh Brigade # Captain: Lady Artoria Evermont, seasoned warrior respected by troops and merchants Lieutenant: Sir Retix Salamandria Marshal-at-Arms: Lady Cassandra Clemont Knight Strategist: Lady Tiger Saka Specialty: Resolving mercantile disputes before they turn violent.\nTimmaeus Brigades # Upper Timmaeus\nCaptain: Sir Blythe Silvercrest, stern upholder of tradition Lieutenant: Alexander Morcent Marshal-at-Arms: Sir Charles d‚ÄôArthur Knight Strategist: Sir Merlin IV Lower Timmaeus\nCaptain: Sir Cade Silvercrest, master of artillery Lieutenant: Tusk of the Mighty Frost Marshal-at-Arms: Sir Lukas Longgo Knight Strategist: Lady Noelle Chevron Responsibility: Protecting the city, the College of Timmaeus, and maintaining peace with the Mighty Frost in the frozen northwest.\nBoljaw Brigade # Captain: Sir Timothy Ballands, charismatic leader beloved by canal dwellers Lieutenant: Alisaile Evermont Marshal-at-Arms: Lady Evienne Barlowe Knight Strategist: Sir Squall Columbus Specialty: Naval engagements and mediating between canal-dwelling factions.\nYarlford Brigade # All Captain and officer posts are currently vacant until the Champion of Valeria appoints new leaders.\nThe Purple Dragon Knights are the embodiment of chivalry and honor, bound by a strict code and admired for their courage and justice.\nThe Syndicates # Felgrand‚Äôs criminal underworld is divided among five major syndicates:\nCoalition of the People\nLed by a council of civic representatives, it provides basic services and social support‚Äîseen by other syndicates as a necessary evil.\nArachnid‚Äôs Fang\nRuled by the enigmatic Spider Queen, this group controls the mercenary guild and executes swift, ruthless justice.\nLegio Ferrum\nA Roman-style legion led by the fearsome Iron General, known for discipline, large armies, and unbreakable loyalty.\nCopper Crown Consortium\nOversees the merchants‚Äô guild and the city‚Äôs economy under the cunning Copper King, using any means to maintain dominance.\nThe Machinist Union\nFounded by the Felgrand family, it drives steampunk innovation and remains officially neutral while navigating shifting alliances.\nHigh Families of Maleketh # Maleketh‚Äôs prosperity rests on four powerful clans:\nBarlowe: Masters of transportation and craftsmanship of carriages and wagons. Megadome: Architects and engineers responsible for public buildings, roads, and bridges. Evermont: Vintners and distributors of wine and spirits, famed for lavish events. Saka: Owners of inns, taverns, and farms, known for culinary excellence and hospitality. Together, these families control Maleketh‚Äôs economy and wield immense influence.\nThe Hunting Guild # In Taloncroft, on the Felgrand‚ÄìMaleketh border, the Talon Hunters defend the town from monsters and dark magic.\nCouncil of Elders: Guides the guild‚Äôs decisions Notable Achievements: Legendary hunts recorded on the Leaderboard of Valor Protection against beasts, witches, undead, and bandits The Talon Hunters are celebrated heroes whose legend inspires the people of Taloncroft.\n","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/worlds/1747764051629-valeria-alliances/","section":"","summary":"","title":"Valeria‚Äôs Alliances: How Knights, Syndicates \u0026 Families Control the Realm","type":"worlds"},{"content":"Image generated by DALL¬∑E 3 via ChatGPT\nValerian Pantheon # The gods and primordial beings of Valeria embody the greatest forces of the cosmos, from celestial light and mortal fate to dragonfire and infernal darkness. Their deeds and domains shape the world and guide the hearts of mortals.\nSeraphim Archangel Inpu Solomon As-Sajdah The Great Salamandria Lady Fortuna Arkus the Horned Reigadyrth Todesfall Aegir Seraphim Archangel # Seraphim Archangel, ruler of the plane of Aether, is a celestial being of immense power and grace. With burnished-brass skin, spun-gold hair, and wings that gleam like sunlight, he wields a flaming sword whose righteous fury banishes darkness. His voice thunders like a thousand trumpets, inspiring hope and striking fear into evil hearts.\nInpu # Inpu, Lord of Embalming and Keeper of the Dead, appears as a jackal-headed humanoid in gold-and-blue ceremonial garb. His knowledge of death and the afterlife commands both reverence and dread. Piercing eyes seem to peer into the soul, and every step echoes beyond the mortal plane.\nSolomon As-Sajdah # Solomon As-Sajdah, the Grim Reaper of souls, guides the departed to their final rest. Cloaked in raven-black robes, his glinting eyes watch over dark forces that would corrupt the dead. Though fearsome in duty, rare acts of mercy speak to a deeper compassion beneath his hood.\nThe Great Salamandria # In the primordial war that forged Valeria, The Great Salamandria roamed as a dragon of living flame. Her sunlike scales and diamond-bright eyes brought warmth and light, yet her pride made her untamable. Vanished after the war‚Äôs end, she remains a symbol of raw power and mystery.\nLady Fortuna # Lady Fortuna, weaver of mortal destinies, appears in visions as either radiant with scarlet hair or cloaked in shadow. Through prayers and offerings, mortals seek her favor‚Äîyet her blessings and curses follow her inscrutable will, for she is fate incarnate.\nArkus the Horned # Arkus the Horned, ruler of the Nether, stands amid infernal fire in coal-black armor etched with ancient runes. His jagged horns and malevolent sneer mark him as master of demons. A cunning strategist, he wields honeyed poison in words and summons abyssal hordes in battle.\nReigadyrth # Reigadyrth, the amethyst-scaled noble dragon, inspired the founding of the Purple Dragon Knights. With thunderous roars and molten flame, she defended mortals from tyranny. Her wisdom endures in the knights‚Äô code of honor and justice.\nTodesfall # Todesfall, brother to Reigadyrth, personifies death‚Äôs finality. Once a glorious dragon, a self-made curse blackened his scales and ragged wings. Now he dwells in solitude, awaiting the end of dragons and the world they shaped.\nAegir # Aegir, king of the frost giants atop Skathi Peak, towers clad in shimmering fur. His hammer of living ice sends shockwaves that freeze enemies solid. Just and honorable to oath-keepers, he unleashes the storm‚Äôs full fury upon traitors.\n","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/worlds/1747764066021-valeria-gods/","section":"","summary":"","title":"Valerian Pantheon: Ultimate Guide to Gods \u0026 Primordials","type":"worlds"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/series/welcome-to-valeria/","section":"Series","summary":"","title":"Welcome to Valeria","type":"series"},{"content":"","date":"1 May 2022","externalUrl":null,"permalink":"/my-work/tags/world-building/","section":"Tags","summary":"","title":"World-Building","type":"tags"},{"content":"Photo by Tofan Teodor on Unsplash\nIntroduction # Have you ever read through a machine learning (ML) toolkit documentation and felt lost? Maybe you have a basic idea of some functions, but not how they work? Modern ML systems often reduce complex operations to hidden processes, leaving users with a mysterious ‚Äúblack box‚Äù that ingests data and churns out predictions without revealing how they work. For beginners, this abstraction might make your job easier, but you never truly learn what certain functions do. In reality, configuring algorithms and debugging errors happen behind the scenes, like assembling a puzzle with half the pieces invisible.\nTo tackle this gap, our research introduces an interactive sandbox: a block-based playground where learners step through each stage of an ML pipeline, visualize algorithmic steps, and build intuition by discovery rather than memorizing code. Grounded in interviews with ten novice and expert ML users, we distilled five design pillars that form the blueprint for a truly user-friendly ML sandbox!\nThe Black-Box Challenge in Machine Learning # At the heart of many ML suites lies a black box, where complex algorithms and data transformations are hidden from the user‚Äôs view. This leaves novices in the dark about how their inputs become outputs. This abstraction shields users from underlying complexity but also fosters a sense of helplessness when experiments fail or yield unexpected results. Classic ML tools often forgo transparency for convenience, bundling data cleaning, feature selection, and model building into monolithic workflows that offer little explanatory feedback. Without clear visibility into each step, learners miss opportunities to build intuition about algorithm behavior, turning what should be a hands-on exploration into a frustrating guessing game.\nConsider two popular visual-pipeline tools:\nWEKA floods users with Java Exception errors when an unknown data type appears. RapidMiner‚Äôs drag-and-drop simplicity belies strict file-formatting rules and cryptic error messages that derail novices at every turn. Meanwhile, code-based libraries like Scikit-Learn offer unmatched flexibility but swap intrusive interfaces for opaque functions. This patchwork of abstracted processes across tools highlights the urgent need for interactive environments that lay bare the machinery of learning algorithms.\nIntroducing the Sandbox Paradigm # Imagine stepping into a safe, virtual playground where you can tinker with data and algorithms without fear of breaking anything. That‚Äôs the core of the sandbox paradigm: an isolated computing environment that lets programs run and users experiment freely, without affecting the underlying system or requiring perfect inputs every time.\nThis idea isn‚Äôt new to computer science education. Scratch, the block-based programming language from MIT, uses a sandbox-like interface so novices can drag, drop, and connect code blocks to create animations and games. Studies have shown that high-school students grasp fundamental programming concepts more quickly when they‚Äôre freed from the distractions of typing and debugging code, focusing instead on logic and structure.\nWhen we look at ML, many existing algorithm-visualization tools fall short of true interactivity. Early efforts provided static animations of clustering or sorting algorithms, but left users wondering how their own choices would influence the model. More recent work, like spreadsheet-based ML explorers and the TensorFlow Neural Network Playground, moves toward real-time, direct-manipulation feedback. Yet they often lack explanatory guidance that ties user actions back to algorithmic behavior.\nWe want to fill this gap using visual workflows with transparent feedback designed using clear user-centered guidelines. We can create a playground where novices shape their experiments, learn from every click, and build robust mental models of how each algorithm works. In the next section, we‚Äôll dive into our grounded research journey that led to those guidelines and see how they pave the way for a new ML learning environment.\nOur Grounded, User-Centric Research Journey # Keeping our users in mind, we anchored our work in a three-phase, user-centered iterative methodology:\nPhase 1: Understanding Needs\nIn-depth interviews with ten participants (novices through experts) Guided by three question sets: ML background and tool usage Specific usability pain points Reactions to a hypothetical block-based ML sandbox Literature review and mapping to prior human-centered ML frameworks Phase 2: Prototyping\nBuilt a minimum viable sandbox featuring block workflows, live visualizations, and context-sensitive hints Phase 3: Evaluation\nUsability studies with novices and ML/HCI experts Iterative refinement of both the tool and the guiding principles Uncovering User Needs # In Phase 1, we recruited ten computing students and professionals through purposive sampling, spanning true novices, learners who had taken an ML course, and practicing ML experts. Each participant sat for an in-depth interview, and we also reviewed relevant literature to inform our initial design considerations.\nSynthesizing Insights into Guidelines # After collecting interview data, we ran an affinity-mapping session to cluster users‚Äô verbatim comments into thematic insights, which crystallized our core problem statements. Participants then rated draft guidelines on a 4-point Likert scale before we finalized our five design pillars. We also distilled personas embodying our three user archetypes to keep their goals and frustrations front and center.\nIterative Prototyping and Evaluation # Guided by these grounded insights, Phase 2 launched our sandbox prototype, featuring block-based workflows, live algorithm visualizations, and context-sensitive hints. In Phase 3, ML and HCI experts joined novice users in usability studies to verify and refine both the tool and the underlying guidelines. This build-test loop ensures that every design decision remains rooted in real learner needs, bringing us closer to a sandbox that demystifies ML for everyone.\nSneak Peek: From Guidelines to Prototype # Throughout our study, we listened closely to both novices fumbling with data blocks and experts probing algorithmic nuances, capturing their insights in affinity maps that formed the heart of our five design guidelines. You‚Äôll also get a firsthand look at how those guidelines breathe life into interactive mock-ups, complete with block-based workflows and live feedback loops.\nAdditionally, see how we put these prototypes through their paces: novices and seasoned ML users alike tested, critiqued, and helped us evolve the sandbox across two more phases of iterative design and usability evaluation. If you want to dive into the full methodology, detailed personas, and the roadmap for future development, head over to our paper and collaborate with us!\nInterested in my research? The take a look at my other works that cover topics ranging from using AI in Live-Prototyping Studies to Affective State Change using Haptics!\n","date":"9 April 2019","externalUrl":null,"permalink":"/my-work/posts/1747834982834-trex/","section":"","summary":"","title":"Exploring the Interactive ML Sandbox: A Guided Discovery","type":"posts"},{"content":"","date":"9 April 2019","externalUrl":null,"permalink":"/my-work/tags/interactive-learning/","section":"Tags","summary":"","title":"Interactive Learning","type":"tags"},{"content":"","date":"9 April 2019","externalUrl":null,"permalink":"/my-work/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning","type":"tags"},{"content":"","date":"9 April 2019","externalUrl":null,"permalink":"/my-work/tags/sandbox/","section":"Tags","summary":"","title":"Sandbox","type":"tags"},{"content":"","date":"9 April 2019","externalUrl":null,"permalink":"/my-work/tags/visualization/","section":"Tags","summary":"","title":"Visualization","type":"tags"},{"content":"","externalUrl":null,"permalink":"/my-work/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/my-work/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]